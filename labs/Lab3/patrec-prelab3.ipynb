{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-15T12:40:26.988225Z",
     "iopub.status.busy": "2022-01-15T12:40:26.987951Z",
     "iopub.status.idle": "2022-01-15T12:40:26.998569Z",
     "shell.execute_reply": "2022-01-15T12:40:26.997586Z",
     "shell.execute_reply.started": "2022-01-15T12:40:26.988196Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import librosa.display as display\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import copy\n",
    "\n",
    "import sklearn\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import seaborn as sns\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "from collections import Counter\n",
    "\n",
    "# Torch\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset, SubsetRandomSampler\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-01-15T12:40:27.001140Z",
     "iopub.status.busy": "2022-01-15T12:40:27.000652Z",
     "iopub.status.idle": "2022-01-15T12:40:27.008672Z",
     "shell.execute_reply": "2022-01-15T12:40:27.007812Z",
     "shell.execute_reply.started": "2022-01-15T12:40:27.001102Z"
    }
   },
   "outputs": [],
   "source": [
    "# To add the competition data Click File->Add or Upload data-> Search by URL -> https://www.kaggle.com/geoparslp/patreco3-multitask-affective-music\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "for dirname, _, filenames in os.walk('./kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Βήμα 1: Εξοικείωση με φασματογραφήματα στην κλίμακα mel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "α) Διαλέγουμε δύο τυχαίες γραμμές του dataset με διαφορετικές επισημειώσεις."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-15T12:40:27.011098Z",
     "iopub.status.busy": "2022-01-15T12:40:27.010361Z",
     "iopub.status.idle": "2022-01-15T12:40:27.036678Z",
     "shell.execute_reply": "2022-01-15T12:40:27.036000Z",
     "shell.execute_reply.started": "2022-01-15T12:40:27.011051Z"
    }
   },
   "outputs": [],
   "source": [
    "# Step 1: Spectograms in mel-scale\n",
    "url_train_labels = '/kaggle/input/patreco3-multitask-affective-music/data/fma_genre_spectrograms/train_labels.txt'\n",
    "my_file = open(url_train_labels, \"r\")\n",
    "content_list = my_file.readlines()\n",
    "\n",
    "# Pick two random lines with diferrent labels\n",
    "print(content_list[1])\n",
    "print(content_list[500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-15T12:40:27.040034Z",
     "iopub.status.busy": "2022-01-15T12:40:27.039668Z",
     "iopub.status.idle": "2022-01-15T12:40:27.609838Z",
     "shell.execute_reply": "2022-01-15T12:40:27.609239Z",
     "shell.execute_reply.started": "2022-01-15T12:40:27.040003Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read Corresponging Files\n",
    "spec1 = np.load('../input/patreco3-multitask-affective-music/data/fma_genre_spectrograms/train/1042.fused.full.npy')\n",
    "spec2 = np.load('../input/patreco3-multitask-affective-music/data/fma_genre_spectrograms/train/1325.fused.full.npy')\n",
    "\n",
    "# Decompose to mel spectogram and chromagram\n",
    "mel1, chroma1 = spec1[:128], spec1[128:]\n",
    "mel2, chroma2 = spec2[:128], spec2[128:]\n",
    "\n",
    "# Visualize spectograms\n",
    "display.specshow(mel1, x_axis = 's', y_axis='mel')\n",
    "plt.show()\n",
    "display.specshow(mel2, x_axis = 's', y_axis='mel')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Βήμα 2: Συγχρονισμός φασματογραφημάτων στο ρυθμό της μουσικής (beat-synced spectrograms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-15T12:40:27.611662Z",
     "iopub.status.busy": "2022-01-15T12:40:27.611215Z",
     "iopub.status.idle": "2022-01-15T12:40:27.617207Z",
     "shell.execute_reply": "2022-01-15T12:40:27.616421Z",
     "shell.execute_reply.started": "2022-01-15T12:40:27.611625Z"
    }
   },
   "outputs": [],
   "source": [
    "# Step 2: Beat-synced spectograms\n",
    "print('Dimensions of the two Spectograms before Beat-Sync:')\n",
    "print(mel1.shape) \n",
    "print(mel2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-15T12:40:27.619536Z",
     "iopub.status.busy": "2022-01-15T12:40:27.618245Z",
     "iopub.status.idle": "2022-01-15T12:40:27.898636Z",
     "shell.execute_reply": "2022-01-15T12:40:27.897948Z",
     "shell.execute_reply.started": "2022-01-15T12:40:27.619505Z"
    }
   },
   "outputs": [],
   "source": [
    "# Repeat Step 1 for beat-synced samples\n",
    "spec1_beat = np.load('../input/patreco3-multitask-affective-music/data/fma_genre_spectrograms_beat/train/1042.fused.full.npy')\n",
    "spec2_beat = np.load('../input/patreco3-multitask-affective-music/data/fma_genre_spectrograms_beat/train/1325.fused.full.npy')\n",
    "\n",
    "# Decompose to mel spectogram and chromagram\n",
    "mel1_beat, chroma1_beat = spec1_beat[:128], spec1_beat[128:]\n",
    "mel2_beat, chroma2_beat = spec2_beat[:128], spec2_beat[128:]\n",
    "\n",
    "# Visualize spectograms\n",
    "display.specshow(mel1_beat, x_axis = 's', y_axis='mel')\n",
    "plt.show()\n",
    "display.specshow(mel2_beat, x_axis = 's', y_axis='mel')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-15T12:40:27.900557Z",
     "iopub.status.busy": "2022-01-15T12:40:27.899722Z",
     "iopub.status.idle": "2022-01-15T12:40:27.906557Z",
     "shell.execute_reply": "2022-01-15T12:40:27.905702Z",
     "shell.execute_reply.started": "2022-01-15T12:40:27.900519Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Dimensions of the two Spectograms after Beat-Sync:')\n",
    "print(mel1_beat.shape) \n",
    "print(mel2_beat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Βήμα 3: Εξοικείωση με χρωμογραφήματα"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-15T12:40:27.908588Z",
     "iopub.status.busy": "2022-01-15T12:40:27.908034Z",
     "iopub.status.idle": "2022-01-15T12:40:28.186692Z",
     "shell.execute_reply": "2022-01-15T12:40:28.184656Z",
     "shell.execute_reply.started": "2022-01-15T12:40:27.908553Z"
    }
   },
   "outputs": [],
   "source": [
    "# Visualize chromagrams\n",
    "display.specshow(chroma1, x_axis = 's', y_axis='mel')\n",
    "plt.show()\n",
    "display.specshow(chroma2, x_axis = 's', y_axis='mel')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-15T12:40:28.189765Z",
     "iopub.status.busy": "2022-01-15T12:40:28.189181Z",
     "iopub.status.idle": "2022-01-15T12:40:28.194110Z",
     "shell.execute_reply": "2022-01-15T12:40:28.193316Z",
     "shell.execute_reply.started": "2022-01-15T12:40:28.189735Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Dimensions of the two Chromagrams before Beat-Sync:')\n",
    "print(chroma1.shape) \n",
    "print(chroma2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-15T12:40:28.197890Z",
     "iopub.status.busy": "2022-01-15T12:40:28.197268Z",
     "iopub.status.idle": "2022-01-15T12:40:28.455976Z",
     "shell.execute_reply": "2022-01-15T12:40:28.455324Z",
     "shell.execute_reply.started": "2022-01-15T12:40:28.197835Z"
    }
   },
   "outputs": [],
   "source": [
    "# Visualize spectograms\n",
    "display.specshow(chroma1_beat, x_axis = 's', y_axis='mel')\n",
    "plt.show()\n",
    "display.specshow(chroma2_beat, x_axis = 's', y_axis='mel')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-15T12:40:28.457492Z",
     "iopub.status.busy": "2022-01-15T12:40:28.457167Z",
     "iopub.status.idle": "2022-01-15T12:40:28.463622Z",
     "shell.execute_reply": "2022-01-15T12:40:28.462826Z",
     "shell.execute_reply.started": "2022-01-15T12:40:28.457455Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Dimensions of the two Chromagrams after Beat-Sync:')\n",
    "print(chroma1_beat.shape) \n",
    "print(chroma2_beat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Βήμα 4: Φόρτωση και ανάλυση δεδομένων"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-15T12:40:28.465902Z",
     "iopub.status.busy": "2022-01-15T12:40:28.465288Z",
     "iopub.status.idle": "2022-01-15T12:40:28.493596Z",
     "shell.execute_reply": "2022-01-15T12:40:28.492675Z",
     "shell.execute_reply.started": "2022-01-15T12:40:28.465862Z"
    }
   },
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "# HINT: Use this class mapping to merge similar classes and ignore classes that do not work very well\n",
    "CLASS_MAPPING = {\n",
    "    \"Rock\": \"Rock\",\n",
    "    \"Psych-Rock\": \"Rock\",\n",
    "    \"Indie-Rock\": None,\n",
    "    \"Post-Rock\": \"Rock\",\n",
    "    \"Psych-Folk\": \"Folk\",\n",
    "    \"Folk\": \"Folk\",\n",
    "    \"Metal\": \"Metal\",\n",
    "    \"Punk\": \"Metal\",\n",
    "    \"Post-Punk\": None,\n",
    "    \"Trip-Hop\": \"Trip-Hop\",\n",
    "    \"Pop\": \"Pop\",\n",
    "    \"Electronic\": \"Electronic\",\n",
    "    \"Hip-Hop\": \"Hip-Hop\",\n",
    "    \"Classical\": \"Classical\",\n",
    "    \"Blues\": \"Blues\",\n",
    "    \"Chiptune\": \"Electronic\",\n",
    "    \"Jazz\": \"Jazz\",\n",
    "    \"Soundtrack\": None,\n",
    "    \"International\": None,\n",
    "    \"Old-Time\": None,\n",
    "}\n",
    "\n",
    "\n",
    "def torch_train_val_split(\n",
    "    dataset, batch_train, batch_eval, val_size=0.2, shuffle=True, seed=420\n",
    "):\n",
    "    # Creating data indices for training and validation splits:\n",
    "    dataset_size = len(dataset)\n",
    "    indices = list(range(dataset_size))\n",
    "    val_split = int(np.floor(val_size * dataset_size))\n",
    "    if shuffle:\n",
    "        np.random.seed(seed)\n",
    "        np.random.shuffle(indices)\n",
    "    train_indices = indices[val_split:]\n",
    "    val_indices = indices[:val_split]\n",
    "\n",
    "    # Creating PT data samplers and loaders:\n",
    "    train_sampler = SubsetRandomSampler(train_indices)\n",
    "    val_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "    train_loader = DataLoader(dataset, batch_size=batch_train, sampler=train_sampler)\n",
    "    val_loader = DataLoader(dataset, batch_size=batch_eval, sampler=val_sampler)\n",
    "    return train_loader, val_loader\n",
    "\n",
    "\n",
    "def read_spectrogram(spectrogram_file, mode = 'fused'):\n",
    "    \n",
    "    if mode == 'mel_spec': # mel-spectogram only\n",
    "        spectrograms = np.load(spectrogram_file)[:128]\n",
    "    elif mode == 'chroma': # chromagram only\n",
    "        spectrograms = np.load(spectrogram_file)[128:]\n",
    "    else: # fused mel spectrogram and chromagram\n",
    "        spectrograms = np.load(spectrogram_file)\n",
    "    return spectrograms.T\n",
    "\n",
    "\n",
    "class LabelTransformer(LabelEncoder):\n",
    "    def inverse(self, y):\n",
    "        try:\n",
    "            return super(LabelTransformer, self).inverse_transform(y)\n",
    "        except:\n",
    "            return super(LabelTransformer, self).inverse_transform([y])\n",
    "\n",
    "    def transform(self, y):\n",
    "        try:\n",
    "            return super(LabelTransformer, self).transform(y)\n",
    "        except:\n",
    "            return super(LabelTransformer, self).transform([y])\n",
    "\n",
    "\n",
    "class PaddingTransform(object):\n",
    "    def __init__(self, max_length, padding_value=0):\n",
    "        self.max_length = max_length\n",
    "        self.padding_value = padding_value\n",
    "\n",
    "    def __call__(self, s):\n",
    "        if len(s) == self.max_length:\n",
    "            return s\n",
    "\n",
    "        if len(s) > self.max_length:\n",
    "            return s[: self.max_length]\n",
    "\n",
    "        if len(s) < self.max_length:\n",
    "            s1 = copy.deepcopy(s)\n",
    "            pad = np.zeros((self.max_length - s.shape[0], s.shape[1]), dtype=np.float32)\n",
    "            s1 = np.vstack((s1, pad))\n",
    "            return s1\n",
    "\n",
    "\n",
    "class SpectrogramDataset(Dataset):\n",
    "    def __init__(\n",
    "        self, path, class_mapping=None, train=True, max_length=-1, regression=None, mode='fused'\n",
    "    ):\n",
    "        t = \"train\" if train else \"test\"\n",
    "        p = os.path.join(path, t)\n",
    "        self.regression = regression\n",
    "\n",
    "        self.index = os.path.join(path, \"{}_labels.txt\".format(t))\n",
    "        self.files, labels = self.get_files_labels(self.index, class_mapping)\n",
    "        self.feats = [read_spectrogram(os.path.join(p, f), mode) for f in self.files]\n",
    "        self.feat_dim = self.feats[0].shape[1]\n",
    "        self.lengths = [len(i) for i in self.feats]\n",
    "        self.max_length = max(self.lengths) if max_length <= 0 else max_length\n",
    "        self.zero_pad_and_stack = PaddingTransform(self.max_length)\n",
    "        self.label_transformer = LabelTransformer()\n",
    "        if isinstance(labels, (list, tuple)):\n",
    "            if not regression:\n",
    "                self.labels = np.array(\n",
    "                    self.label_transformer.fit_transform(labels)\n",
    "                ).astype(\"int64\")\n",
    "            else:\n",
    "                self.labels = np.array(labels).astype(\"float64\")\n",
    "    \n",
    "    def get_files_labels(self, txt, class_mapping):\n",
    "        with open(txt, \"r\") as fd:\n",
    "            lines = [l.rstrip().split(\"\\t\") for l in fd.readlines()[1:]]\n",
    "        files, labels = [], []\n",
    "        for l in lines:\n",
    "            if self.regression:\n",
    "                l = l[0].split(\",\")\n",
    "                files.append(l[0] + \".fused.full.npy\")\n",
    "                labels.append(l[self.regression])\n",
    "                continue\n",
    "            label = l[1]\n",
    "            if class_mapping:\n",
    "                label = class_mapping[l[1]]\n",
    "            if not label:\n",
    "                continue\n",
    "            _id = l[0].split('.')[0]\n",
    "            fname = '{}.fused.full.npy'.format(_id)\n",
    "            files.append(fname)\n",
    "            labels.append(label)\n",
    "        return files, labels\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        length = min(self.lengths[item], self.max_length)\n",
    "        return self.zero_pad_and_stack(self.feats[item]), self.labels[item], length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "##################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-15T12:40:28.495147Z",
     "iopub.status.busy": "2022-01-15T12:40:28.494898Z",
     "iopub.status.idle": "2022-01-15T12:41:14.580595Z",
     "shell.execute_reply": "2022-01-15T12:41:14.579828Z",
     "shell.execute_reply.started": "2022-01-15T12:40:28.495111Z"
    }
   },
   "outputs": [],
   "source": [
    "##### Load mel spectograms (not beat_synced) #####\n",
    "\n",
    "# Load Train Dataset\n",
    "mel_train_set = SpectrogramDataset('../input/patreco3-multitask-affective-music/data/fma_genre_spectrograms/', train=True,\n",
    "                                     class_mapping=CLASS_MAPPING, max_length=-1,\n",
    "                                     mode = 'mel_spec')\n",
    "# Train and Val loaders - Batch Size = 32\n",
    "train_loader_mel, val_loader_mel = torch_train_val_split(mel_train_set, 32, 32, val_size=.33)\n",
    "\n",
    "# Load Test Dataset\n",
    "mel_test_set = SpectrogramDataset('../input/patreco3-multitask-affective-music/data/fma_genre_spectrograms/', train=False,\n",
    "                                             class_mapping=CLASS_MAPPING, max_length=-1,\n",
    "                                             mode = 'mel_spec')\n",
    "# Test Loader - Batch Size = 1\n",
    "test_loader_mel = DataLoader(mel_test_set, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-15T12:41:14.583645Z",
     "iopub.status.busy": "2022-01-15T12:41:14.581864Z",
     "iopub.status.idle": "2022-01-15T12:41:27.705991Z",
     "shell.execute_reply": "2022-01-15T12:41:27.705257Z",
     "shell.execute_reply.started": "2022-01-15T12:41:14.583611Z"
    }
   },
   "outputs": [],
   "source": [
    "##### Load beat-synced mel spectograms #####\n",
    "\n",
    "# Load Train Dataset\n",
    "beat_mel_train_set = SpectrogramDataset('../input/patreco3-multitask-affective-music/data/fma_genre_spectrograms_beat/', train=True,\n",
    "                                     class_mapping=CLASS_MAPPING, max_length=-1,\n",
    "                                     mode = 'mel_spec')\n",
    "# Train and Val loaders - Batch Size = 32\n",
    "train_loader_beat_mel, val_loader_beat_mel = torch_train_val_split(beat_mel_train_set, 32, 32, val_size=.33)\n",
    "\n",
    "# Load Test Dataset\n",
    "beat_mel_test_set = SpectrogramDataset('../input/patreco3-multitask-affective-music/data/fma_genre_spectrograms_beat/', train=False,\n",
    "                                             class_mapping=CLASS_MAPPING, max_length=-1,\n",
    "                                             mode = 'mel_spec')\n",
    "# Test Loader - Batch Size = 1\n",
    "test_loader_beat_mel = DataLoader(beat_mel_test_set, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-15T12:41:27.708831Z",
     "iopub.status.busy": "2022-01-15T12:41:27.708320Z",
     "iopub.status.idle": "2022-01-15T12:41:30.328297Z",
     "shell.execute_reply": "2022-01-15T12:41:30.327546Z",
     "shell.execute_reply.started": "2022-01-15T12:41:27.708792Z"
    }
   },
   "outputs": [],
   "source": [
    "##### Load beat-synced chromagrams #####\n",
    "\n",
    "# Load Train Dataset\n",
    "beat_chroma_train_set = SpectrogramDataset('../input/patreco3-multitask-affective-music/data/fma_genre_spectrograms_beat/', train=True,\n",
    "                                     class_mapping=CLASS_MAPPING, max_length=-1,\n",
    "                                     mode = 'chroma')\n",
    "# Train and Val loaders - Batch Size = 32\n",
    "train_loader_beat_chroma, val_loader_beat_chroma = torch_train_val_split(beat_chroma_train_set, 32, 32, val_size=.33)\n",
    "\n",
    "# Load Test Dataset\n",
    "beat_chroma_test_set = SpectrogramDataset('../input/patreco3-multitask-affective-music/data/fma_genre_spectrograms_beat/', train=False,\n",
    "                                             class_mapping=CLASS_MAPPING, max_length=-1,\n",
    "                                             mode = 'chroma')\n",
    "# Test Loader - Batch Size = 1\n",
    "test_loader_beat_chroma = DataLoader(beat_chroma_test_set, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-15T12:41:30.329910Z",
     "iopub.status.busy": "2022-01-15T12:41:30.329673Z",
     "iopub.status.idle": "2022-01-15T12:41:32.956963Z",
     "shell.execute_reply": "2022-01-15T12:41:32.956246Z",
     "shell.execute_reply.started": "2022-01-15T12:41:30.329876Z"
    }
   },
   "outputs": [],
   "source": [
    "##### Load beat-synced fused mel spectograms & chromagrams #####\n",
    "\n",
    "# Load Train Dataset\n",
    "beat_train_set_fused = SpectrogramDataset('../input/patreco3-multitask-affective-music/data/fma_genre_spectrograms_beat/', train=True,\n",
    "                                     class_mapping=CLASS_MAPPING, max_length=-1,\n",
    "                                     mode = 'fused')\n",
    "# Train and Val loaders - Batch Size = 32\n",
    "train_loader_beat_fused, val_loader_beat_fused = torch_train_val_split(beat_train_set_fused, 32, 32, val_size=.33)\n",
    "\n",
    "# Load Test Dataset\n",
    "beat_test_set_fused = SpectrogramDataset('../input/patreco3-multitask-affective-music/data/fma_genre_spectrograms_beat/', train=False,\n",
    "                                             class_mapping=CLASS_MAPPING, max_length=-1,\n",
    "                                             mode = 'fused')\n",
    "# Test Loader - Batch Size = 1\n",
    "test_loader_beat_fused = DataLoader(beat_test_set_fused, batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Δημιουργούμε τα **ιστογράμματα** κλάσεων πριν και μετά τη συγχώνευση/αφαίρεση κλάσεων."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-15T12:41:32.959663Z",
     "iopub.status.busy": "2022-01-15T12:41:32.959263Z",
     "iopub.status.idle": "2022-01-15T12:41:32.968130Z",
     "shell.execute_reply": "2022-01-15T12:41:32.967449Z",
     "shell.execute_reply.started": "2022-01-15T12:41:32.959627Z"
    }
   },
   "outputs": [],
   "source": [
    "# (c) Histograms before and after Class Mapping\n",
    "\n",
    "# Read Labels of Train and Test Dataset\n",
    "def read_file(txt_file):\n",
    "    output = []\n",
    "    file = open(txt_file, 'r') \n",
    "    Lines = file.readlines()[1:] \n",
    "    for line in Lines: \n",
    "        element = line.split()[1]\n",
    "        output.append(element)\n",
    "    return output\n",
    "\n",
    "y_train = read_file('../input/patreco3-multitask-affective-music/data/fma_genre_spectrograms_beat/train_labels.txt')\n",
    "y_test = read_file('../input/patreco3-multitask-affective-music/data/fma_genre_spectrograms_beat/test_labels.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-15T12:41:32.969686Z",
     "iopub.status.busy": "2022-01-15T12:41:32.969367Z",
     "iopub.status.idle": "2022-01-15T12:41:32.976887Z",
     "shell.execute_reply": "2022-01-15T12:41:32.976109Z",
     "shell.execute_reply.started": "2022-01-15T12:41:32.969651Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_bar(labels, palette = \"Blues_d\"):\n",
    "    f = plt.figure()\n",
    "    f.set_figwidth(30)\n",
    "    f.set_figheight(10)\n",
    "    freqs = list(Counter(labels).values())\n",
    "    sns.set(style=\"darkgrid\")\n",
    "    sns.barplot(np.unique(labels), freqs, alpha=0.9, palette=palette)\n",
    "    plt.ylabel('Number of Occurrences', fontsize=12)\n",
    "    plt.xlabel('Music Genres', fontsize=12)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-15T12:41:32.978257Z",
     "iopub.status.busy": "2022-01-15T12:41:32.977915Z",
     "iopub.status.idle": "2022-01-15T12:41:33.400813Z",
     "shell.execute_reply": "2022-01-15T12:41:33.400117Z",
     "shell.execute_reply.started": "2022-01-15T12:41:32.978222Z"
    }
   },
   "outputs": [],
   "source": [
    "# Histograms before Category Mapping\n",
    "# Train Set\n",
    "plot_bar(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-15T12:41:33.402533Z",
     "iopub.status.busy": "2022-01-15T12:41:33.401822Z",
     "iopub.status.idle": "2022-01-15T12:41:33.917081Z",
     "shell.execute_reply": "2022-01-15T12:41:33.916407Z",
     "shell.execute_reply.started": "2022-01-15T12:41:33.402486Z"
    }
   },
   "outputs": [],
   "source": [
    "# Test Set\n",
    "plot_bar(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-15T12:41:33.918837Z",
     "iopub.status.busy": "2022-01-15T12:41:33.918591Z",
     "iopub.status.idle": "2022-01-15T12:41:33.925088Z",
     "shell.execute_reply": "2022-01-15T12:41:33.924457Z",
     "shell.execute_reply.started": "2022-01-15T12:41:33.918803Z"
    }
   },
   "outputs": [],
   "source": [
    "# Histograms after Category Mapping\n",
    "y_train_mapped = []\n",
    "for genre in y_train:\n",
    "    if CLASS_MAPPING[genre]:\n",
    "        y_train_mapped.append(CLASS_MAPPING[genre])\n",
    "\n",
    "y_test_mapped = []\n",
    "for genre in y_test:\n",
    "    if CLASS_MAPPING[genre]:\n",
    "        y_test_mapped.append(CLASS_MAPPING[genre])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-15T12:41:33.926793Z",
     "iopub.status.busy": "2022-01-15T12:41:33.926165Z",
     "iopub.status.idle": "2022-01-15T12:41:33.939947Z",
     "shell.execute_reply": "2022-01-15T12:41:33.939185Z",
     "shell.execute_reply.started": "2022-01-15T12:41:33.926751Z"
    }
   },
   "outputs": [],
   "source": [
    "np.unique(y_train_mapped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-15T12:41:33.942766Z",
     "iopub.status.busy": "2022-01-15T12:41:33.942088Z",
     "iopub.status.idle": "2022-01-15T12:41:34.255053Z",
     "shell.execute_reply": "2022-01-15T12:41:34.254311Z",
     "shell.execute_reply.started": "2022-01-15T12:41:33.942731Z"
    }
   },
   "outputs": [],
   "source": [
    "# Train Set\n",
    "plot_bar(y_train_mapped, 'Reds_d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-15T12:41:34.257563Z",
     "iopub.status.busy": "2022-01-15T12:41:34.256239Z",
     "iopub.status.idle": "2022-01-15T12:41:34.559057Z",
     "shell.execute_reply": "2022-01-15T12:41:34.558292Z",
     "shell.execute_reply.started": "2022-01-15T12:41:34.257518Z"
    }
   },
   "outputs": [],
   "source": [
    "# Test Set\n",
    "plot_bar(y_test_mapped, 'Reds_d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Βήμα 5: Αναγνώριση μουσικού είδους με LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-15T12:41:34.560869Z",
     "iopub.status.busy": "2022-01-15T12:41:34.560492Z",
     "iopub.status.idle": "2022-01-15T12:41:34.586436Z",
     "shell.execute_reply": "2022-01-15T12:41:34.585669Z",
     "shell.execute_reply.started": "2022-01-15T12:41:34.560829Z"
    }
   },
   "outputs": [],
   "source": [
    "# Lab 2 Basic LSTM Class\n",
    "class BasicLSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_size, output_dim, num_layers, bidirectional=False, dropout = 0):\n",
    "        super(BasicLSTM, self).__init__()\n",
    "        self.bidirectional = bidirectional\n",
    "        self.feature_size = hidden_size * 2 if self.bidirectional else hidden_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # --------------- Insert your code here ---------------- #\n",
    "        # Initialize the LSTM, Dropout, Output layers\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_size, num_layers, bidirectional=self.bidirectional, batch_first=True, dropout=dropout)\n",
    "        self.linear = nn.Linear(self.feature_size, output_dim)\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        \"\"\" \n",
    "            x : 3D numpy array of dimension N x L x D\n",
    "                N: batch index\n",
    "                L: sequence index\n",
    "                D: feature index\n",
    "\n",
    "            lengths: N x 1\n",
    "         \"\"\"\n",
    "        \n",
    "        # --------------- Insert your code here ---------------- #\n",
    "        \n",
    "        # You must have all of the outputs of the LSTM, but you need only the last one (that does not exceed the sequence length)\n",
    "        # To get it use the last_timestep method\n",
    "        # Then pass it through the remaining network\n",
    "        \n",
    "        if self.bidirectional:\n",
    "            num_layers = 2*self.num_layers\n",
    "        else:\n",
    "            num_layers = self.num_layers\n",
    "            \n",
    "        DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "        h0 = torch.zeros(num_layers, x.size(0), self.hidden_size).double().to(DEVICE)\n",
    "        c0 = torch.zeros(num_layers, x.size(0), self.hidden_size).double().to(DEVICE)\n",
    "\n",
    "        # Forward through LSTM\n",
    "        hn, _ = self.lstm(x, (h0, c0))\n",
    "        # Final Linear Layer - pass last timestep\n",
    "        last_outputs = self.linear(self.last_timestep(hn, lengths, self.bidirectional))\n",
    "\n",
    "        return last_outputs\n",
    "\n",
    "    def last_timestep(self, outputs, lengths, bidirectional=False):\n",
    "        \"\"\"\n",
    "            Returns the last output of the LSTM taking into account the zero padding\n",
    "        \"\"\"\n",
    "        if bidirectional:\n",
    "            forward, backward = self.split_directions(outputs)\n",
    "            last_forward = self.last_by_index(forward, lengths)\n",
    "            last_backward = backward[:, 0, :]\n",
    "            # Concatenate and return - maybe add more functionalities like average\n",
    "            return torch.cat((last_forward, last_backward), dim=-1)\n",
    "\n",
    "        else:\n",
    "            return self.last_by_index(outputs, lengths)\n",
    "\n",
    "    @staticmethod\n",
    "    def split_directions(outputs):\n",
    "        direction_size = int(outputs.size(-1) / 2)\n",
    "        forward = outputs[:, :, :direction_size]\n",
    "        backward = outputs[:, :, direction_size:]\n",
    "        return forward, backward\n",
    "\n",
    "    @staticmethod\n",
    "    def last_by_index(outputs, lengths):\n",
    "        # Index of the last output for each sequence.\n",
    "        idx = (lengths - 1).view(-1, 1).expand(outputs.size(0),\n",
    "                                               outputs.size(2)).unsqueeze(1)\n",
    "        return outputs.gather(1, idx).squeeze()\n",
    "\n",
    "class BasicLSTM_packed(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_size, output_dim, num_layers, bidirectional=False, dropout = 0):\n",
    "        super(BasicLSTM_packed, self).__init__()\n",
    "        self.bidirectional = bidirectional\n",
    "        self.feature_size = hidden_size * 2 if self.bidirectional else hidden_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # --------------- Insert your code here ---------------- #\n",
    "        # Initialize the LSTM, Dropout, Output layers\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_size, num_layers, bidirectional=self.bidirectional, batch_first=True, dropout=dropout)\n",
    "        self.linear = nn.Linear(self.feature_size, output_dim)\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        \"\"\" \n",
    "            x : 3D numpy array of dimension N x L x D\n",
    "                N: batch index\n",
    "                L: sequence index\n",
    "                D: feature index\n",
    "\n",
    "            lengths: N x 1\n",
    "         \"\"\"\n",
    "        \n",
    "        # --------------- Insert your code here ---------------- #\n",
    "        \n",
    "        # You must have all of the outputs of the LSTM, but you need only the last one (that does not exceed the sequence length)\n",
    "        # To get it use the last_timestep method\n",
    "        # Then pass it through the remaining network\n",
    "        \n",
    "        if self.bidirectional:\n",
    "            num_layers = 2*self.num_layers\n",
    "        else:\n",
    "            num_layers = self.num_layers\n",
    "\n",
    "        h0 = torch.zeros(num_layers, x.size(0), self.hidden_size).to(DEVICE)\n",
    "        c0 = torch.zeros(num_layers, x.size(0), self.hidden_size).to(DEVICE)\n",
    "        \n",
    "        # Sort Inputs by decreasing length\n",
    "        lengths, indices = lengths.sort(dim = 0, descending = True)\n",
    "        x = x[indices] \n",
    "\n",
    "        packed_x = pack_padded_sequence(x, list(lengths.data), batch_first=True, enforce_sorted = True)\n",
    "        \n",
    "        # Forward through LSTM\n",
    "        hn, _ = self.lstm(packed_x, (h0, c0))\n",
    "        hn = pad_packed_sequence(hn, batch_first=True)[0]\n",
    "\n",
    "        # Final Linear Layer - pass last timestep\n",
    "        last_outputs = self.linear(self.last_timestep(hn, lengths, self.bidirectional))\n",
    "\n",
    "        return last_outputs, indices # also return indices to allign data with labels\n",
    "\n",
    "    def last_timestep(self, outputs, lengths, bidirectional=False):\n",
    "        \"\"\"\n",
    "            Returns the last output of the LSTM taking into account the zero padding\n",
    "        \"\"\"\n",
    "        if bidirectional:\n",
    "            forward, backward = self.split_directions(outputs)\n",
    "            last_forward = self.last_by_index(forward, lengths)\n",
    "            last_backward = backward[:, 0, :]\n",
    "            # Concatenate and return - maybe add more functionalities like average\n",
    "            return torch.cat((last_forward, last_backward), dim=-1)\n",
    "\n",
    "        else:\n",
    "            return self.last_by_index(outputs, lengths)\n",
    "\n",
    "    @staticmethod\n",
    "    def split_directions(outputs):\n",
    "        direction_size = int(outputs.size(-1) / 2)\n",
    "        forward = outputs[:, :, :direction_size]\n",
    "        backward = outputs[:, :, direction_size:]\n",
    "        return forward, backward\n",
    "\n",
    "    @staticmethod\n",
    "    def last_by_index(outputs, lengths):\n",
    "        # Index of the last output for each sequence.\n",
    "        idx = (lengths - 1).view(-1, 1).expand(outputs.size(0),\n",
    "                                               outputs.size(2)).unsqueeze(1)\n",
    "        return outputs.gather(1, idx).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-15T12:41:34.588604Z",
     "iopub.status.busy": "2022-01-15T12:41:34.587747Z",
     "iopub.status.idle": "2022-01-15T12:41:34.609471Z",
     "shell.execute_reply": "2022-01-15T12:41:34.608782Z",
     "shell.execute_reply.started": "2022-01-15T12:41:34.588568Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function that Trains a Neural Network\n",
    "def train_NN(dataloader, model, criterion, optimizer, device1, packed = False, overfit_batch = False):\n",
    "    total_loss = 0.0\n",
    "    model.train() # switch to train mode\n",
    "    device = next(model.parameters()).device\n",
    "    \n",
    "    for idx, batch in enumerate(dataloader, 1):\n",
    "        \n",
    "        # Unpack Batch\n",
    "        (inputs, labels, lengths) = batch\n",
    "        \n",
    "        # Convert to Double\n",
    "        inputs.double()\n",
    "        lengths.double()\n",
    "\n",
    "        # Move the batch tensors to the right device\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        lengths = lengths.to(device)\n",
    "        \n",
    "        # Zero Gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if packed: # allign labels with sorted input\n",
    "            # Forward Pass\n",
    "            y_preds, indices = model(inputs, lengths)\n",
    "\n",
    "            # Compute Loss\n",
    "            loss = criterion(y_preds, labels[indices])\n",
    "        else:\n",
    "            # Forward Pass\n",
    "            y_preds = model(inputs, lengths)\n",
    "\n",
    "            # Compute Loss\n",
    "            loss = criterion(y_preds, labels)\n",
    "\n",
    "        # Back-Propagate Loss\n",
    "        loss.backward()\n",
    "\n",
    "        # Update Loss\n",
    "        optimizer.step()\n",
    "\n",
    "        # Collect Loss\n",
    "        total_loss += loss.data.item()\n",
    "\n",
    "    return total_loss/idx\n",
    "\n",
    "# Function that Evaluates a Neural Network\n",
    "def eval_NN(dataloader, model, criterion, device, packed = False):\n",
    "    \n",
    "    total_loss = 0.0\n",
    "    model.eval() # switch to evaluation mode\n",
    "    \n",
    "    y_gold = []\n",
    "    y_pred = []\n",
    "    \n",
    "    with torch.no_grad(): # don't keep gradients\n",
    "        for idx, batch in enumerate(dataloader, 1):\n",
    "            \n",
    "            (inputs, labels, lengths) = batch\n",
    "            \n",
    "            # Convert to Double\n",
    "            inputs.double()\n",
    "            lengths.double()\n",
    "\n",
    "            # Move the batch tensors to the right device\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            lengths = lengths.to(device)\n",
    "            \n",
    "            \n",
    "            if packed: # allign labels with sorted input\n",
    "                # Forward Pass\n",
    "                y_preds, indices = model(inputs, lengths)\n",
    "\n",
    "                # Compute Loss\n",
    "                loss = criterion(y_preds, labels[indices])\n",
    "            else:\n",
    "                # Forward Pass\n",
    "                y_preds = model(inputs, lengths)\n",
    "\n",
    "                # Compute Loss\n",
    "                loss = criterion(y_preds, labels)\n",
    "            \n",
    "            # Prediction: argmax of aposterioris\n",
    "            prediction = torch.argmax(y_preds, dim=1)\n",
    "            \n",
    "            # Collect Loss and labels\n",
    "            total_loss += loss.data.item()\n",
    "            \n",
    "            y_pred.append(prediction.cpu().numpy())\n",
    "            if packed:\n",
    "                y_gold.append(labels[indices].numpy())\n",
    "            else:\n",
    "                y_gold.append(labels.cpu().numpy())\n",
    "\n",
    "    return total_loss / idx, (y_gold, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-15T12:41:34.614561Z",
     "iopub.status.busy": "2022-01-15T12:41:34.614328Z",
     "iopub.status.idle": "2022-01-15T12:41:34.620972Z",
     "shell.execute_reply": "2022-01-15T12:41:34.620323Z",
     "shell.execute_reply.started": "2022-01-15T12:41:34.614525Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function that plots train and validation losses for given epochs\n",
    "def plot_losses(epochs, train_loss, val_loss, title = 'Losses per Epoch'):\n",
    "    n = np.arange(epochs)\n",
    "    plt.plot(n, train_loss, label = \"Train Loss\")\n",
    "    plt.plot(n, val_loss, label = \"Validation Loss\")\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(β) **Υπερεκπαίδευση** πάνω σε λίγα batches μέχρι το overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-15T13:02:09.663800Z",
     "iopub.status.busy": "2022-01-15T13:02:09.663330Z",
     "iopub.status.idle": "2022-01-15T13:02:09.675246Z",
     "shell.execute_reply": "2022-01-15T13:02:09.674233Z",
     "shell.execute_reply.started": "2022-01-15T13:02:09.663761Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\"\n",
    "Main pipeline of Neural Network:\n",
    "- Trains model on Train Dataset\n",
    "- Evaluates on Validation Set\n",
    "- Plots Train and Validation Loss per Epoch\n",
    "\n",
    "If overfi_batch==True: DEBUG_MODE\n",
    "Overfit on a few train batches and return accumulated train loss\n",
    "\"\"\"\n",
    "def NN_pipeline(model, train_set, criterion, optimizer, EPOCHS, DEVICE, overfit_batch = False, packed = False, save_name='model'):\n",
    "    \n",
    "    # Lists to collect train and validaiton loss\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    # Early Stopping Hyperparameters\n",
    "    counter = 0\n",
    "    max_increases = 10\n",
    "    best_val_loss = 9999999\n",
    "    \n",
    "    if overfit_batch: # USED FOR DEBUGGING\n",
    "        # Use class Subset to get 4 first batches only for debugging\n",
    "        subset = torch.utils.data.Subset(train_set, [i for i in range(4)])\n",
    "        train_loader = DataLoader(subset, batch_size=2)\n",
    "        \n",
    "        for epoch in range(EPOCHS):\n",
    "            # fit model\n",
    "            train_loss = train_NN(train_loader, model, criterion, optimizer, DEVICE, packed)\n",
    "            print('EPOCH',str(epoch),':')\n",
    "            print('Training Loss:',str(train_loss))    \n",
    "            train_losses.append(train_loss)\n",
    "        \n",
    "        return train_losses\n",
    "\n",
    "    else:\n",
    "        train_loader, val_loader = torch_train_val_split(train_set, 32, 32, val_size=.33) # split train/val\n",
    "        \n",
    "        for epoch in range(EPOCHS):\n",
    "            # fit model\n",
    "            train_loss = train_NN(train_loader, model, criterion, optimizer, DEVICE, packed)\n",
    "\n",
    "            print('EPOCH',str(epoch),':')\n",
    "            print('Training Loss:',str(train_loss))    \n",
    "            train_losses.append(train_loss)\n",
    "\n",
    "            # evaluate on validation set - comment out if unwanted\n",
    "            val_loss, (y_gold, y_pred) = eval_NN(val_loader, model, criterion, DEVICE, packed)\n",
    "            print('Validation Loss:',str(val_loss))\n",
    "            val_losses.append(val_loss)\n",
    "            \n",
    "            # Apply Early Stopping Techniques\n",
    "            if val_loss < best_val_loss:\n",
    "                torch.save(model, save_name) # checkpoint\n",
    "                best_val_loss = val_loss\n",
    "                counter = 0 # reset counter\n",
    "            else:\n",
    "                counter += 1\n",
    "\n",
    "            if counter == max_increases: # 10 times in a row no loss improvement - break\n",
    "                print('Early Stopping')\n",
    "                break\n",
    "\n",
    "        plot_losses(len(train_losses), train_losses, val_losses, title = 'Losses per Epoch - Bidirectional LSTM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-15T12:41:34.635664Z",
     "iopub.status.busy": "2022-01-15T12:41:34.634971Z",
     "iopub.status.idle": "2022-01-15T12:41:34.693019Z",
     "shell.execute_reply": "2022-01-15T12:41:34.692379Z",
     "shell.execute_reply.started": "2022-01-15T12:41:34.635628Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define n_features for each case and n_classes of classification problem\n",
    "n_feats_mel = beat_mel_train_set[0][0].shape[1] #128 features\n",
    "n_feats_chroma = beat_chroma_train_set[0][0].shape[1] # 12 features\n",
    "n_classes = len(np.unique(y_train_mapped)) # 10 classes\n",
    "\n",
    "# Check for GPUs\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-15T12:48:23.026511Z",
     "iopub.status.busy": "2022-01-15T12:48:23.025924Z",
     "iopub.status.idle": "2022-01-15T12:48:23.063058Z",
     "shell.execute_reply": "2022-01-15T12:48:23.062235Z",
     "shell.execute_reply.started": "2022-01-15T12:48:23.026468Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define Model and Hyperparameters - Implement L2-Regularization and Dropout\n",
    "model = BasicLSTM(input_dim = n_feats_mel, hidden_size = 256, \n",
    "                       output_dim = n_classes, num_layers = 2, bidirectional=True, dropout = 0.5)\n",
    "model.double()\n",
    "model.to(DEVICE)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-5)\n",
    "EPOCHS = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# (b) OVERFIT MODEL FOR DEBUGGING\n",
    "train_losses = NN_pipeline(model, mel_train_set, criterion, optimizer, EPOCHS, DEVICE, overfit_batch = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-13T17:49:49.516182Z",
     "iopub.status.busy": "2022-01-13T17:49:49.515485Z",
     "iopub.status.idle": "2022-01-13T17:49:49.732299Z",
     "shell.execute_reply": "2022-01-13T17:49:49.731646Z",
     "shell.execute_reply.started": "2022-01-13T17:49:49.516145Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot([i+1 for i in range(0,EPOCHS)], train_losses)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Train Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "γ) Εκπαιδεύστε ένα LSTM [15] δίκτυο, το οποίο θα δέχεται ως είσοδο τα φασματογραφήματα\n",
    "του συνόλου εκπαίδευσης (train set) και θα προβλέπει τις διαφορετικές κλάσεις (μουσικά είδη)\n",
    "του συνόλου δεδομένων (dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-15T13:16:40.413335Z",
     "iopub.status.busy": "2022-01-15T13:16:40.413057Z",
     "iopub.status.idle": "2022-01-15T13:16:40.450676Z",
     "shell.execute_reply": "2022-01-15T13:16:40.449880Z",
     "shell.execute_reply.started": "2022-01-15T13:16:40.413303Z"
    }
   },
   "outputs": [],
   "source": [
    "# (c) LSTM on mel-spectograms\n",
    "modelC = BasicLSTM(input_dim = n_feats_mel, hidden_size = 256, \n",
    "                       output_dim = n_classes, num_layers = 2, bidirectional=True, dropout = 0.5)\n",
    "modelC.double()\n",
    "modelC.to(DEVICE)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(modelC.parameters(), lr=0.0001, weight_decay=1e-5)\n",
    "EPOCHS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-15T13:16:41.004454Z",
     "iopub.status.busy": "2022-01-15T13:16:41.003868Z",
     "iopub.status.idle": "2022-01-15T13:30:29.970225Z",
     "shell.execute_reply": "2022-01-15T13:30:29.968562Z",
     "shell.execute_reply.started": "2022-01-15T13:16:41.004406Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "NN_pipeline(modelC, mel_train_set, criterion, optimizer, EPOCHS, DEVICE, save_name = './best_modelC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "δ) εκπαιδεύστε ένα LSTM δίκτυο, το οποίο θα δέχεται ως είσοδο τα beat-synced spectrograms\n",
    "(train set) και θα προβλέπει τις διαφορετικές κλάσεις (μουσικά είδη) του συνόλου δεδομένων."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-15T13:03:01.809101Z",
     "iopub.status.busy": "2022-01-15T13:03:01.808656Z",
     "iopub.status.idle": "2022-01-15T13:03:01.843860Z",
     "shell.execute_reply": "2022-01-15T13:03:01.843145Z",
     "shell.execute_reply.started": "2022-01-15T13:03:01.809064Z"
    }
   },
   "outputs": [],
   "source": [
    "# (d) LSTM on beat-synced mel-spectograms\n",
    "modelD = BasicLSTM(input_dim = n_feats_mel, hidden_size = 256, \n",
    "                       output_dim = n_classes, num_layers = 2, bidirectional=True, dropout = 0.5)\n",
    "modelD.double()\n",
    "modelD.to(DEVICE)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(modelD.parameters(), lr=0.0001, weight_decay=1e-5)\n",
    "EPOCHS = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-15T13:03:09.244947Z",
     "iopub.status.busy": "2022-01-15T13:03:09.244261Z",
     "iopub.status.idle": "2022-01-15T13:05:16.554859Z",
     "shell.execute_reply": "2022-01-15T13:05:16.553376Z",
     "shell.execute_reply.started": "2022-01-15T13:03:09.244907Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "NN_pipeline(modelD, beat_mel_train_set, criterion, optimizer, EPOCHS, DEVICE, save_name = './best_modelD')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ε) εκπαιδεύστε ένα LSTM δίκτυο, το οποίο θα δέχεται ως είσοδο τα χρωμογραφήματα (train set)\n",
    "και θα προβλέπει τις διαφορετικές κλάσεις (μουσικά είδη) του συνόλου δεδομένων."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-15T13:08:36.916554Z",
     "iopub.status.busy": "2022-01-15T13:08:36.916167Z",
     "iopub.status.idle": "2022-01-15T13:08:36.952172Z",
     "shell.execute_reply": "2022-01-15T13:08:36.951421Z",
     "shell.execute_reply.started": "2022-01-15T13:08:36.916503Z"
    }
   },
   "outputs": [],
   "source": [
    "# (e) LSTM on beat-synced mel-spectograms\n",
    "modelE = BasicLSTM(input_dim = n_feats_chroma, hidden_size = 256, \n",
    "                       output_dim = n_classes, num_layers = 2, bidirectional=True, dropout = 0.5)\n",
    "modelE.double()\n",
    "modelE.to(DEVICE)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(modelE.parameters(), lr=0.0001, weight_decay=1e-5)\n",
    "EPOCHS = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-15T13:09:07.580853Z",
     "iopub.status.busy": "2022-01-15T13:09:07.580598Z",
     "iopub.status.idle": "2022-01-15T13:11:25.467856Z",
     "shell.execute_reply": "2022-01-15T13:11:25.466288Z",
     "shell.execute_reply.started": "2022-01-15T13:09:07.580824Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "NN_pipeline(modelE, beat_chroma_train_set, criterion, optimizer, EPOCHS, DEVICE, save_name='./best_modelE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ζ) (extra credit) εκπαιδεύστε ένα LSTM δίκτυο, το οποίο θα δέχεται ως είσοδο τα ενωμένα\n",
    "(concatenated) χρωμογραφήματα και φασματογραφήματα (train set) και θα προβλέπει τις\n",
    "διαφορετικές κλάσεις (μουσικά είδη) του συνόλου δεδομένων."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-15T13:12:24.780010Z",
     "iopub.status.busy": "2022-01-15T13:12:24.779386Z",
     "iopub.status.idle": "2022-01-15T13:12:24.818612Z",
     "shell.execute_reply": "2022-01-15T13:12:24.817830Z",
     "shell.execute_reply.started": "2022-01-15T13:12:24.779969Z"
    }
   },
   "outputs": [],
   "source": [
    "# (z) LSTM on beat-synced mel-spectograms\n",
    "modelZ = BasicLSTM(input_dim = n_feats_chroma+n_feats_mel, hidden_size = 256, \n",
    "                       output_dim = n_classes, num_layers = 2, bidirectional=True, dropout = 0.5)\n",
    "modelZ.double()\n",
    "modelZ.to(DEVICE)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(modelZ.parameters(), lr=0.0001, weight_decay=1e-5)\n",
    "EPOCHS = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-15T13:12:37.052133Z",
     "iopub.status.busy": "2022-01-15T13:12:37.051447Z",
     "iopub.status.idle": "2022-01-15T13:15:11.744967Z",
     "shell.execute_reply": "2022-01-15T13:15:11.744268Z",
     "shell.execute_reply.started": "2022-01-15T13:12:37.052092Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "NN_pipeline(modelZ, beat_train_set_fused, criterion, optimizer, EPOCHS, DEVICE, save_name='./best_modelZ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Βήμα 6: Αξιολόγηση των μοντέλων"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-15T13:30:29.972150Z",
     "iopub.status.busy": "2022-01-15T13:30:29.971830Z",
     "iopub.status.idle": "2022-01-15T13:30:30.016073Z",
     "shell.execute_reply": "2022-01-15T13:30:30.015355Z",
     "shell.execute_reply.started": "2022-01-15T13:30:29.972111Z"
    }
   },
   "outputs": [],
   "source": [
    "# Step 6: Evaluation of Models\n",
    "\n",
    "# Load Best Models of Early Stopping\n",
    "modelC = torch.load('./best_modelC')\n",
    "modelD = torch.load('./best_modelD')\n",
    "modelE = torch.load('./best_modelE')\n",
    "modelZ = torch.load('./best_modelZ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-15T12:57:01.648056Z",
     "iopub.status.busy": "2022-01-15T12:57:01.647338Z",
     "iopub.status.idle": "2022-01-15T12:57:01.652614Z",
     "shell.execute_reply": "2022-01-15T12:57:01.651825Z",
     "shell.execute_reply.started": "2022-01-15T12:57:01.648018Z"
    }
   },
   "outputs": [],
   "source": [
    "def test_report(model, test_loader, criterion, DEVICE, packed = False):\n",
    "    test_loss, (y_gold, y_pred) = eval_NN(test_loader, model, criterion, DEVICE, packed)    \n",
    "    return classification_report(np.concatenate(y_gold), np.concatenate(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-15T13:30:30.017926Z",
     "iopub.status.busy": "2022-01-15T13:30:30.017644Z",
     "iopub.status.idle": "2022-01-15T13:30:35.691903Z",
     "shell.execute_reply": "2022-01-15T13:30:35.691092Z",
     "shell.execute_reply.started": "2022-01-15T13:30:30.017890Z"
    }
   },
   "outputs": [],
   "source": [
    "# Evaluate Case (c) on Test Set\n",
    "print(test_report(modelC, test_loader_mel, criterion, DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-15T13:08:01.179470Z",
     "iopub.status.busy": "2022-01-15T13:08:01.179196Z",
     "iopub.status.idle": "2022-01-15T13:08:01.705801Z",
     "shell.execute_reply": "2022-01-15T13:08:01.705068Z",
     "shell.execute_reply.started": "2022-01-15T13:08:01.179437Z"
    }
   },
   "outputs": [],
   "source": [
    "# Evaluate Case (d) on Test Set\n",
    "print(test_report(modelD, test_loader_beat_mel, criterion, DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-15T13:11:59.746336Z",
     "iopub.status.busy": "2022-01-15T13:11:59.745804Z",
     "iopub.status.idle": "2022-01-15T13:12:00.233786Z",
     "shell.execute_reply": "2022-01-15T13:12:00.233082Z",
     "shell.execute_reply.started": "2022-01-15T13:11:59.746295Z"
    }
   },
   "outputs": [],
   "source": [
    "# Evaluate Case (e) on Test Set\n",
    "print(test_report(modelE, test_loader_beat_chroma, criterion, DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-15T13:15:41.244788Z",
     "iopub.status.busy": "2022-01-15T13:15:41.244533Z",
     "iopub.status.idle": "2022-01-15T13:15:41.785927Z",
     "shell.execute_reply": "2022-01-15T13:15:41.785193Z",
     "shell.execute_reply.started": "2022-01-15T13:15:41.244761Z"
    }
   },
   "outputs": [],
   "source": [
    "# Evaluate Case (z) on Test Set\n",
    "print(test_report(modelZ, test_loader_beat_fused, criterion, DEVICE))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
