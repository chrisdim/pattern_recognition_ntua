{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Import Libraries\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport librosa.display as display\nimport matplotlib.pyplot as plt\nimport os\nimport copy\n\nimport sklearn\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import classification_report\nfrom scipy.stats import spearmanr\n\nimport seaborn as sns\nsns.set_style(\"darkgrid\", {\"axes.facecolor\": \".9\"})\nimport warnings \nwarnings.filterwarnings('ignore')\nfrom collections import Counter\n\n# Torch\nimport torch\nfrom torch.utils.data import DataLoader, Dataset, SubsetRandomSampler\nfrom torch.utils.data import Dataset\nimport torch.nn as nn\nfrom torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\nimport joblib","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-28T20:19:25.610018Z","iopub.execute_input":"2022-02-28T20:19:25.610489Z","iopub.status.idle":"2022-02-28T20:19:28.915417Z","shell.execute_reply.started":"2022-02-28T20:19:25.61038Z","shell.execute_reply":"2022-02-28T20:19:28.914641Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# To add the competition data Click File->Add or Upload data-> Search by URL -> https://www.kaggle.com/geoparslp/patreco3-multitask-affective-music\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nfor dirname, _, filenames in os.walk('./kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"execution":{"iopub.status.busy":"2022-02-28T20:19:28.917196Z","iopub.execute_input":"2022-02-28T20:19:28.91745Z","iopub.status.idle":"2022-02-28T20:19:28.923272Z","shell.execute_reply.started":"2022-02-28T20:19:28.917416Z","shell.execute_reply":"2022-02-28T20:19:28.922166Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False\nis_cuda = torch.cuda.is_available()\n\n# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\nif is_cuda:\n    device = torch.device(\"cuda\")\nelse:\n    device = torch.device(\"cpu\")","metadata":{"execution":{"iopub.status.busy":"2022-02-28T20:19:28.924711Z","iopub.execute_input":"2022-02-28T20:19:28.925249Z","iopub.status.idle":"2022-02-28T20:19:28.971186Z","shell.execute_reply.started":"2022-02-28T20:19:28.925207Z","shell.execute_reply":"2022-02-28T20:19:28.970403Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Χρήσιμες Συναρτήσεις Προπαρασκευής","metadata":{}},{"cell_type":"code","source":"##################################################################################\n# HINT: Use this class mapping to merge similar classes and ignore classes that do not work very well\nCLASS_MAPPING = {\n    \"Rock\": \"Rock\",\n    \"Psych-Rock\": \"Rock\",\n    \"Indie-Rock\": None,\n    \"Post-Rock\": \"Rock\",\n    \"Psych-Folk\": \"Folk\",\n    \"Folk\": \"Folk\",\n    \"Metal\": \"Metal\",\n    \"Punk\": \"Metal\",\n    \"Post-Punk\": None,\n    \"Trip-Hop\": \"Trip-Hop\",\n    \"Pop\": \"Pop\",\n    \"Electronic\": \"Electronic\",\n    \"Hip-Hop\": \"Hip-Hop\",\n    \"Classical\": \"Classical\",\n    \"Blues\": \"Blues\",\n    \"Chiptune\": \"Electronic\",\n    \"Jazz\": \"Jazz\",\n    \"Soundtrack\": None,\n    \"International\": None,\n    \"Old-Time\": None,\n}\n\n\ndef torch_train_val_split(\n    dataset, batch_train, batch_eval, val_size=0.2, shuffle=True, seed=420\n):\n    # Creating data indices for training and validation splits:\n    dataset_size = len(dataset)\n    indices = list(range(dataset_size))\n    val_split = int(np.floor(val_size * dataset_size))\n    if shuffle:\n        np.random.seed(seed)\n        np.random.shuffle(indices)\n    train_indices = indices[val_split:]\n    val_indices = indices[:val_split]\n\n    # Creating PT data samplers and loaders:\n    train_sampler = SubsetRandomSampler(train_indices)\n    val_sampler = SubsetRandomSampler(val_indices)\n\n    train_loader = DataLoader(dataset, batch_size=batch_train, sampler=train_sampler)\n    val_loader = DataLoader(dataset, batch_size=batch_eval, sampler=val_sampler)\n    return train_loader, val_loader\n\n\ndef read_spectrogram(spectrogram_file, mode = 'fused'):\n    \n    if mode == 'mel_spec': # mel-spectogram only\n        spectrograms = np.load(spectrogram_file)[:128]\n    elif mode == 'chroma': # chromagram only\n        spectrograms = np.load(spectrogram_file)[128:]\n    else: # fused mel spectrogram and chromagram\n        spectrograms = np.load(spectrogram_file)\n    return spectrograms.T\n\n\nclass LabelTransformer(LabelEncoder):\n    def inverse(self, y):\n        try:\n            return super(LabelTransformer, self).inverse_transform(y)\n        except:\n            return super(LabelTransformer, self).inverse_transform([y])\n\n    def transform(self, y):\n        try:\n            return super(LabelTransformer, self).transform(y)\n        except:\n            return super(LabelTransformer, self).transform([y])\n\n\nclass PaddingTransform(object):\n    def __init__(self, max_length, padding_value=0):\n        self.max_length = max_length\n        self.padding_value = padding_value\n\n    def __call__(self, s):\n        if len(s) == self.max_length:\n            return s\n\n        if len(s) > self.max_length:\n            return s[: self.max_length]\n\n        if len(s) < self.max_length:\n            s1 = copy.deepcopy(s)\n            pad = np.zeros((self.max_length - s.shape[0], s.shape[1]), dtype=np.float32)\n            s1 = np.vstack((s1, pad))\n            return s1\n\n\nclass SpectrogramDataset(Dataset):\n    def __init__(\n        self, path, class_mapping=None, train=True, max_length=-1, regression=None, mode='mel_spec'\n    ):\n        t = \"train\" if train else \"test\"\n        p = os.path.join(path, t)\n        self.regression = regression\n\n        self.index = os.path.join(path, \"{}_labels.txt\".format(t))\n        self.files, labels = self.get_files_labels(self.index, class_mapping)\n        self.feats = [read_spectrogram(os.path.join(p, f), mode) for f in self.files]\n        self.feat_dim = self.feats[0].shape[1]\n        self.lengths = [len(i) for i in self.feats]\n        self.max_length = max(self.lengths) if max_length <= 0 else max_length\n        self.zero_pad_and_stack = PaddingTransform(self.max_length)\n        self.label_transformer = LabelTransformer()\n        if isinstance(labels, (list, tuple)):\n            if not regression:\n                self.labels = np.array(\n                    self.label_transformer.fit_transform(labels)\n                ).astype(\"int64\")\n            else:\n                self.labels = np.array(labels).astype(\"float64\")\n    \n    def get_files_labels(self, txt, class_mapping):\n        with open(txt, \"r\") as fd:\n            lines = [l.rstrip().split(\"\\t\") for l in fd.readlines()[1:]]\n        files, labels = [], []\n        for l in lines:\n            if self.regression:\n                l = l[0].split(\",\")\n                files.append(l[0] + \".fused.full.npy\")\n                labels.append(l[self.regression])\n                continue\n            label = l[1]\n            if class_mapping:\n                label = class_mapping[l[1]]\n            if not label:\n                continue\n            _id = l[0].split('.')[0]\n            fname = '{}.fused.full.npy'.format(_id)\n            files.append(fname)\n            labels.append(label)\n        return files, labels\n\n    def __getitem__(self, item):\n        length = min(self.lengths[item], self.max_length)\n        return self.zero_pad_and_stack(self.feats[item]), self.labels[item], length\n\n    def __len__(self):\n        return len(self.labels)\n\n##################################################################################","metadata":{"execution":{"iopub.status.busy":"2022-02-28T20:19:29.320007Z","iopub.execute_input":"2022-02-28T20:19:29.320688Z","iopub.status.idle":"2022-02-28T20:19:29.35934Z","shell.execute_reply.started":"2022-02-28T20:19:29.320641Z","shell.execute_reply":"2022-02-28T20:19:29.358613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##### Load mel spectograms (not beat_synced) #####\n\n# Load Train Dataset\nmel_train_set = SpectrogramDataset('../input/patreco3-multitask-affective-music/data/fma_genre_spectrograms/', train=True,\n                                     class_mapping=CLASS_MAPPING, max_length=-1,\n                                     mode = 'mel_spec')\n# Train and Val loaders - Batch Size = 32\ntrain_loader_mel, val_loader_mel = torch_train_val_split(mel_train_set, 32, 32, val_size=.33)\n\n# Load Test Dataset\nmel_test_set = SpectrogramDataset('../input/patreco3-multitask-affective-music/data/fma_genre_spectrograms/', train=False,\n                                             class_mapping=CLASS_MAPPING, max_length=-1,\n                                             mode = 'mel_spec')\n# Test Loader - Batch Size = 1\ntest_loader_mel = DataLoader(mel_test_set, batch_size=16)","metadata":{"execution":{"iopub.status.busy":"2022-02-28T18:59:28.791483Z","iopub.execute_input":"2022-02-28T18:59:28.792247Z","iopub.status.idle":"2022-02-28T19:00:17.576404Z","shell.execute_reply.started":"2022-02-28T18:59:28.792199Z","shell.execute_reply":"2022-02-28T19:00:17.575532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Lab 2 Basic LSTM Class\nclass BasicLSTM(nn.Module):\n    def __init__(self, input_dim, hidden_size, output_dim, num_layers, bidirectional=False, dropout = 0):\n        super(BasicLSTM, self).__init__()\n        self.bidirectional = bidirectional\n        self.feature_size = hidden_size * 2 if self.bidirectional else hidden_size\n        self.hidden_size = hidden_size\n        self.num_layers = num_layers\n\n        # --------------- Insert your code here ---------------- #\n        # Initialize the LSTM, Dropout, Output layers\n        self.lstm = nn.LSTM(input_dim, hidden_size, num_layers, bidirectional=self.bidirectional, batch_first=True, dropout=dropout)\n        self.linear = nn.Linear(self.feature_size, output_dim)\n\n    def forward(self, x, lengths):\n        \"\"\" \n            x : 3D numpy array of dimension N x L x D\n                N: batch index\n                L: sequence index\n                D: feature index\n\n            lengths: N x 1\n         \"\"\"\n        \n        # --------------- Insert your code here ---------------- #\n        \n        # You must have all of the outputs of the LSTM, but you need only the last one (that does not exceed the sequence length)\n        # To get it use the last_timestep method\n        # Then pass it through the remaining network\n        \n        if self.bidirectional:\n            num_layers = 2*self.num_layers\n        else:\n            num_layers = self.num_layers\n            \n        DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n        \n        h0 = torch.zeros(num_layers, x.size(0), self.hidden_size).to(DEVICE).double()\n        c0 = torch.zeros(num_layers, x.size(0), self.hidden_size).to(DEVICE).double()\n\n        # Forward through LSTM\n        hn, _ = self.lstm(x, (h0, c0))\n        # Final Linear Layer - pass last timestep\n        last_outputs = self.linear(self.last_timestep(hn, lengths, self.bidirectional))\n\n        return last_outputs\n\n    def last_timestep(self, outputs, lengths, bidirectional=False):\n        \"\"\"\n            Returns the last output of the LSTM taking into account the zero padding\n        \"\"\"\n        if bidirectional:\n            forward, backward = self.split_directions(outputs)\n            last_forward = self.last_by_index(forward, lengths)\n            last_backward = backward[:, 0, :]\n            # Concatenate and return - maybe add more functionalities like average\n            return torch.cat((last_forward, last_backward), dim=-1)\n\n        else:\n            return self.last_by_index(outputs, lengths)\n\n    @staticmethod\n    def split_directions(outputs):\n        direction_size = int(outputs.size(-1) / 2)\n        forward = outputs[:, :, :direction_size]\n        backward = outputs[:, :, direction_size:]\n        return forward, backward\n\n    @staticmethod\n    def last_by_index(outputs, lengths):\n        # Index of the last output for each sequence.\n        idx = (lengths - 1).view(-1, 1).expand(outputs.size(0),\n                                               outputs.size(2)).unsqueeze(1)\n        return outputs.gather(1, idx).squeeze()","metadata":{"execution":{"iopub.status.busy":"2022-02-28T19:00:17.578227Z","iopub.execute_input":"2022-02-28T19:00:17.578651Z","iopub.status.idle":"2022-02-28T19:00:17.599495Z","shell.execute_reply.started":"2022-02-28T19:00:17.578612Z","shell.execute_reply":"2022-02-28T19:00:17.598468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function that Evaluates a Convolutional Neural Network\ndef eval_NN(dataloader, model, criterion, regression = False, is_CNN = True):\n    \n    total_loss = 0.0\n    model.eval() # switch to evaluation mode\n    \n    y_gold = []\n    y_pred = []\n    \n    with torch.no_grad(): # don't keep gradients\n        for idx, batch in enumerate(dataloader, 1):\n            \n            (inputs, labels, lengths) = batch\n\n            # Move the batch tensors to the right device\n            inputs = inputs.to(device).float()\n            lengths = lengths.to(device)\n            \n            if not regression:\n                labels = labels.to(device).long()\n            else:\n                labels = labels.to(device).float()\n            \n            # Forward Pass\n            if not is_CNN:\n                inputs = inputs.to(device).double()\n                labels = labels.to(device).double()\n                y_preds = model(inputs, lengths)\n            else:\n                y_preds = model(inputs)\n\n            # Compute Loss\n            loss = criterion(y_preds, labels)\n            \n            # Prediction: argmax of aposterioris\n            if regression:\n                prediction = y_preds\n            else:\n                prediction = torch.argmax(y_preds, dim=1)\n            \n            # Collect Loss and labels\n            total_loss += loss.data.item()\n            \n            y_pred.append(prediction.cpu().numpy())\n            y_gold.append(labels.cpu().numpy())\n\n    return total_loss / idx, (y_gold, y_pred)","metadata":{"execution":{"iopub.status.busy":"2022-02-28T20:19:32.301175Z","iopub.execute_input":"2022-02-28T20:19:32.301649Z","iopub.status.idle":"2022-02-28T20:19:32.312127Z","shell.execute_reply.started":"2022-02-28T20:19:32.301608Z","shell.execute_reply":"2022-02-28T20:19:32.311429Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_LSTM(train_loader, val_loader, epochs, save_dir, lr = 0.001, \n              weight_decay = 0.0001, early_stopping=True):\n    \n    model_lstm = BasicLSTM(input_dim = 128, hidden_size = 128, \n                           output_dim = 1, num_layers = 4,\n                           bidirectional=True, dropout = 0.3).double().to(device)\n    \n    criterion = nn.MSELoss()\n    optimizer = torch.optim.Adam(model_lstm.parameters(), lr=lr, weight_decay=weight_decay)\n\n    loss_values_train = []\n    loss_values_val = []\n    counter=0\n    best_val_loss = 999999\n    max_increases = 10   \n    \n    for i in range(epochs):\n        running_loss_train=0.0\n        train_losses=[]\n        \n        for inputs, labels, lengths in train_loader:\n            model_lstm.train()   \n            inputs, labels, lengths = inputs.to(device), labels.to(device), lengths.to(device)\n            \n            model_lstm.zero_grad()\n            output =  model_lstm(inputs.double(), lengths)\n            loss = criterion(output.squeeze(), labels.double())\n            train_losses.append(loss.item())\n            loss.backward()\n            optimizer.step()\n            \n        val_loss, (y_gold, y_pred) = eval_NN(val_loader, model_lstm, criterion, \n                                             regression=True, is_CNN = False)\n\n        # Collect Losses\n        loss_values_val.append(val_loss)\n        loss_values_train.append(np.mean(train_losses))\n\n\n        print(\"Epoch: {}/{}:\".format(i+1, epochs),\n              \"Train Loss: {:.6f} - \".format(loss.item()),\n              \"Val Loss: {:.6f}\".format(val_loss))\n        \n        \n        # Apply Early Stopping Techniques\n        if val_loss < best_val_loss:\n            torch.save(model_lstm.state_dict(),save_dir) # checkpoint\n            best_val_loss = val_loss\n            gold = y_gold\n            pred = y_pred\n            counter = 0 # reset counter\n        else:\n            counter += 1\n\n        if early_stopping:\n            if counter == max_increases: # 10 times in a row no loss improvement - break\n                print('Early Stopping')\n                break\n            \n    plt.figure()\n    plt.plot(range(len(loss_values_train)),loss_values_train, label = 'Train Loss')\n    plt.plot(range(len(loss_values_val)), loss_values_val, label = 'Validation Loss')\n    plt.xlabel('Epochs')\n    plt.legend()\n    plt.show()\n    \n    torch.save(model_lstm.state_dict(),save_dir) # save best model","metadata":{"execution":{"iopub.status.busy":"2022-02-28T01:32:30.759028Z","iopub.execute_input":"2022-02-28T01:32:30.759295Z","iopub.status.idle":"2022-02-28T01:32:30.772621Z","shell.execute_reply.started":"2022-02-28T01:32:30.759266Z","shell.execute_reply":"2022-02-28T01:32:30.771848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Βήμα 7: 2D CNNs","metadata":{}},{"cell_type":"markdown","source":"Υλοποιούμε ένα 2D CNN με 4 επίπεδα (layers) που θα επεξεργάζεται το φασματογράφημα σαν\nμονοκάναλη εικόνα. Το εκπαιδεύουμε στο train + validation set και αναφέρουμε τα αποτελέσματα\nστο test set. Κάθε επίπεδο θα πραγματοποιεί τις εξής λειτουργίες (operations) με αυτή τη σειρά:\n1) 2D convolution <br/>\n2) Batch normalization <br/>\n3) ReLU activation <br/>\n4) Max pooling","metadata":{}},{"cell_type":"code","source":"class CNN_2D(nn.Module):\n    def __init__(self, output_dim = 10):\n        super(CNN_2D,self).__init__()\n        \n        self.main_body = nn.Sequential(\n            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(32),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2),\n\n            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(64),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2),\n\n            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(128),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=4),\n\n            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(256),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=4),\n            \n        )\n        \n        # Fully Connected Layer\n        self.fc = nn.Sequential(\n            nn.ReLU(),\n            nn.Dropout(),\n            nn.Linear(in_features=10240, out_features=output_dim) #10240\n        )\n\n    def forward(self, x):\n        #we want x to have dimensions [batch_size,1,]\n        x=x.transpose(1,2)\n        x=torch.unsqueeze(x,1)\n        \n        for layer in self.main_body:\n            x = layer(x)\n        \n        x = x.view(x.size(0),-1) # flatten data\n        \n        for layer in self.fc:\n            x=layer(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2022-02-28T20:29:14.513116Z","iopub.execute_input":"2022-02-28T20:29:14.51341Z","iopub.status.idle":"2022-02-28T20:29:14.525152Z","shell.execute_reply.started":"2022-02-28T20:29:14.513378Z","shell.execute_reply":"2022-02-28T20:29:14.524348Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Main Pipeline that Trains on Train Set and Evaluates on Validation Set\ndef train_CNN(data_loader, val_loader, epochs, batch_size, save_dir, lr = 0.001, \n              weight_decay = 0.0001, regression=False, early_stopping = True, load_model = False):\n\n    # Define Hyperparameters and CNN Model        \n    \n    if not regression:\n        model_cnn = CNN_2D(output_dim = 10)\n        criterion=nn.CrossEntropyLoss()\n    else:\n        model_cnn = CNN_2D(output_dim = 1)\n        criterion  = nn.MSELoss()\n    \n    if load_model: # load model for transfer learning\n        \n        # Load CNN Model from Step 7 train on fma spectrograms\n        model_cnn = CNN_2D(output_dim=10).to(device).float()\n        model_cnn.load_state_dict(torch.load(\"CNN_step7\"))\n        \n        # Freeze parameters except from last FC layer\n        for weight in model_cnn.parameters():\n            weight.requires_grad = False\n            \n        model_cnn.fc = nn.Sequential(\n                    nn.ReLU(),\n                    nn.Dropout(),\n                    nn.Linear(in_features=10240, out_features=1) #10240\n                ).to(device)\n        save_dir = \"CNN_transfer\"\n        \n    model_cnn.to(device).float()\n    optimizer = torch.optim.Adam(model_cnn.parameters(), lr=lr,weight_decay=0.0001)\n    \n    train_loss_min = np.Inf\n    loss_values_train = []\n    loss_values_val = []\n    \n    # Early Stopping Hyperparameters\n    counter=0\n    best_val_loss = 999999\n    max_increases = 10\n    \n    model_cnn.train()    \n    for i in range(epochs):\n        running_loss_train=0.0\n        running_loss_val=0.0\n        train_losses=[]\n        for idx, batch in enumerate(data_loader):\n             # Unpack Batch\n            (inputs, labels, lengths) = batch\n            inputs, labels, lengths= inputs.to(device), labels.to(device),lengths.to(device)\n            model_cnn.zero_grad()\n            output =  model_cnn(inputs.float())\n            \n            if not regression:\n                loss = criterion(output.squeeze(), labels.long())\n            else:\n                loss = criterion(output.squeeze(), labels.float())\n            \n            running_loss_train =+ loss.item() * batch_size\n            train_losses.append(loss.item())\n            loss.backward()\n            optimizer.step()\n            \n        val_loss, (y_gold, y_pred)  = eval_NN(val_loader, model_cnn, criterion, regression)\n        loss_values_val.append(val_loss)\n\n        print(\"Epoch: {}/{}:\".format(i+1, epochs),\n              \"Train Loss: {:.6f} - \".format(loss.item()),\n              \"Val Loss: {:.6f}\".format(val_loss))\n        \n        loss_values_train.append(np.mean(train_losses))\n        \n        # Apply Early Stopping Techniques\n        if val_loss < best_val_loss:\n            torch.save(model_cnn.state_dict(),save_dir) # checkpoint\n            best_val_loss = val_loss\n            gold = y_gold\n            pred = y_pred\n            counter = 0 # reset counter\n        else:\n            counter += 1\n\n        if early_stopping:\n            if counter == max_increases: # 10 times in a row no loss improvement - break\n                print('Early Stopping')\n                break\n            \n    plt.figure()\n    plt.plot(range(len(loss_values_train)),loss_values_train, label = 'Train Loss')\n    plt.plot(range(len(loss_values_val)), loss_values_val, label = 'Validation Loss')\n    plt.xlabel('Epochs')\n    plt.legend()\n    plt.show()\n    \n    torch.save(model_cnn.state_dict(),save_dir) # save best model","metadata":{"execution":{"iopub.status.busy":"2022-02-28T19:48:31.904398Z","iopub.execute_input":"2022-02-28T19:48:31.904965Z","iopub.status.idle":"2022-02-28T19:48:31.924168Z","shell.execute_reply.started":"2022-02-28T19:48:31.904934Z","shell.execute_reply":"2022-02-28T19:48:31.923213Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_CNN(train_loader_mel, val_loader_mel, epochs = 30, batch_size = 32, save_dir = 'CNN_step7', regression=False)","metadata":{"execution":{"iopub.status.busy":"2022-02-28T02:38:24.239802Z","iopub.execute_input":"2022-02-28T02:38:24.240319Z","iopub.status.idle":"2022-02-28T02:40:50.715215Z","shell.execute_reply.started":"2022-02-28T02:38:24.24028Z","shell.execute_reply":"2022-02-28T02:40:50.714539Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Classification Report on Test\ndef test_report_CNN(model, test_loader, model_dir, criterion, regression = False):\n    model.load_state_dict(torch.load(model_dir))\n    test_loss, (y_gold, y_pred) = eval_NN(test_loader, model, criterion, regression)    \n    return classification_report(np.concatenate(y_gold), np.concatenate(y_pred))","metadata":{"execution":{"iopub.status.busy":"2022-02-28T02:40:50.71696Z","iopub.execute_input":"2022-02-28T02:40:50.717201Z","iopub.status.idle":"2022-02-28T02:40:50.724275Z","shell.execute_reply.started":"2022-02-28T02:40:50.717166Z","shell.execute_reply":"2022-02-28T02:40:50.723552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cnn_step7 = CNN_2D(10).to(device).float()\ncriterion = nn.CrossEntropyLoss()\nprint(test_report_CNN(cnn_step7, test_loader_mel, 'CNN_step7', criterion, regression = False))","metadata":{"execution":{"iopub.status.busy":"2022-02-28T02:40:50.725382Z","iopub.execute_input":"2022-02-28T02:40:50.725622Z","iopub.status.idle":"2022-02-28T02:40:51.973362Z","shell.execute_reply.started":"2022-02-28T02:40:50.72558Z","shell.execute_reply":"2022-02-28T02:40:51.972637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Βήμα 8: Εκτίμηση συναισθήματος - συμπεριφοράς με παλινδρόμηση","metadata":{}},{"cell_type":"code","source":"# Load Multitask Datasets for Valence (1), Energy (2), Danceability (3)\n\nvalence_dataset = SpectrogramDataset('../input/patreco3-multitask-affective-music/data/multitask_dataset/',\n                            train=True,\n                            class_mapping=None, max_length=-1,\n                            regression=1)\n\nenergy_dataset = SpectrogramDataset('../input/patreco3-multitask-affective-music/data/multitask_dataset/',\n                            train=True,\n                            class_mapping=None, max_length=-1,\n                            regression=2)\n\ndanceability_dataset = SpectrogramDataset('../input/patreco3-multitask-affective-music/data/multitask_dataset/',\n                            train=True,\n                            class_mapping=None, max_length=-1,\n                            regression=3)\n\n# Train - Val Split for each one\ntrain_loader_valence, val_loader_valence = torch_train_val_split(valence_dataset, batch_train=32, batch_eval=32, val_size=.2)\ntrain_loader_energy, val_loader_energy = torch_train_val_split(energy_dataset, batch_train=32, batch_eval=32, val_size=.2)\ntrain_loader_danceability, val_loader_danceability = torch_train_val_split(danceability_dataset, batch_train=32, batch_eval=32, val_size=.2)","metadata":{"execution":{"iopub.status.busy":"2022-02-28T02:43:13.704727Z","iopub.execute_input":"2022-02-28T02:43:13.705476Z","iopub.status.idle":"2022-02-28T02:43:39.319913Z","shell.execute_reply.started":"2022-02-28T02:43:13.705434Z","shell.execute_reply":"2022-02-28T02:43:39.319174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def test_lstm_multitask(test_loader,model_dir):\n    model_lstm = BasicLSTM(input_dim = 128, hidden_size = 128,  bidirectional = True,\n                       output_dim = 1, num_layers = 4, dropout = 0.3)\n    model_lstm.to(device).double()\n    model_lstm.load_state_dict(torch.load(model_dir))\n\n    test_losses = []\n    y_pred_test=[]\n    y_true=[]\n    model_lstm.eval()\n    for inputs, labels,lengths in test_loader:\n        inputs,labels,lengths= inputs.to(device), labels.to(device),lengths.to(device)\n        output = model_lstm(inputs.double(),lengths)\n        y_pred_test.append(output.tolist())\n        y_true.append(labels.tolist())\n        \n    true = np.array(y_true).flatten()\n    pred = np.array(y_pred_test).flatten()\n    \n    # Scatter Plot Predictions - Gold Labels\n    plt.scatter(true, pred)\n    plt.xlabel('y_true')\n    plt.ylabel('y_pred')\n    golden_line = np.linspace(0,1,1000)\n    plt.plot(golden_line,golden_line, '--', color='m')\n    plt.show()\n    \n    rho= spearmanr(np.array(y_true).flatten(),np.array(y_pred_test).flatten()).correlation\n    print('\\nTest set: Spearman Correlation: {:.6f} \\n'.format(rho))\n    return rho","metadata":{"execution":{"iopub.status.busy":"2022-02-28T01:26:26.70387Z","iopub.execute_input":"2022-02-28T01:26:26.704116Z","iopub.status.idle":"2022-02-28T01:26:26.716345Z","shell.execute_reply.started":"2022-02-28T01:26:26.70408Z","shell.execute_reply":"2022-02-28T01:26:26.715545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluate with Spearman Correlation\ndef test_cnn_multitask(test_loader, model_dir):\n    \n    # Fetch Model\n    model_cnn=CNN_2D(output_dim=1).to(device).float()\n    model_cnn.load_state_dict(torch.load(model_dir))\n    \n    test_losses = []\n    y_pred_test=[]\n    y_true=[]\n    model_cnn.eval()\n    for inputs, labels,lengths in test_loader:\n        inputs,labels,lengths= inputs.to(device), labels.to(device),lengths.to(device)\n        output = model_cnn(inputs.float())\n        y_pred_test.append(output.data.tolist())\n        y_true.append(labels.tolist())\n        \n    true = np.array(y_true).flatten()\n    pred = np.array(y_pred_test).flatten()\n    \n    # Scatter Plot Predictions - Gold Labels\n    plt.scatter(true, pred)\n    plt.xlabel('y_true')\n    plt.ylabel('y_pred')\n    golden_line = np.linspace(0,1,1000)\n    plt.plot(golden_line,golden_line, '--', color='m')\n    plt.show()\n    \n    # Ger Spearmann Correlation\n    rho= spearmanr(true,pred).correlation\n    print('\\nTest set: Spearman Correlation: {:.6f} \\n'.format(rho))\n    return rho","metadata":{"execution":{"iopub.status.busy":"2022-02-28T02:45:53.132179Z","iopub.execute_input":"2022-02-28T02:45:53.132511Z","iopub.status.idle":"2022-02-28T02:45:53.141251Z","shell.execute_reply.started":"2022-02-28T02:45:53.132477Z","shell.execute_reply":"2022-02-28T02:45:53.140499Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### (a) Valence Label","metadata":{}},{"cell_type":"code","source":"train_LSTM(train_loader_valence, val_loader_valence, epochs = 30,\n           save_dir = 'LSTM_valence', early_stopping=False)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-02-28T01:32:39.286764Z","iopub.execute_input":"2022-02-28T01:32:39.287329Z","iopub.status.idle":"2022-02-28T01:47:16.943559Z","shell.execute_reply.started":"2022-02-28T01:32:39.287289Z","shell.execute_reply":"2022-02-28T01:47:16.942847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rho_LSTM_valence = test_lstm_multitask(val_loader_valence, 'LSTM_valence')","metadata":{"execution":{"iopub.status.busy":"2022-02-28T01:47:16.945271Z","iopub.execute_input":"2022-02-28T01:47:16.945629Z","iopub.status.idle":"2022-02-28T01:47:19.343823Z","shell.execute_reply.started":"2022-02-28T01:47:16.945589Z","shell.execute_reply":"2022-02-28T01:47:19.342757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_CNN(train_loader_valence, val_loader_valence, epochs = 30, batch_size = 16, save_dir = 'CNN_valence', regression=True, early_stopping = False)","metadata":{"execution":{"iopub.status.busy":"2022-02-27T17:27:01.150012Z","iopub.execute_input":"2022-02-27T17:27:01.15028Z","iopub.status.idle":"2022-02-27T17:29:26.204353Z","shell.execute_reply.started":"2022-02-27T17:27:01.150248Z","shell.execute_reply":"2022-02-27T17:29:26.203688Z"},"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rho_CNN_valence = test_cnn_multitask(val_loader_valence,'CNN_valence')","metadata":{"execution":{"iopub.status.busy":"2022-02-27T17:34:26.688411Z","iopub.execute_input":"2022-02-27T17:34:26.688674Z","iopub.status.idle":"2022-02-27T17:34:27.75134Z","shell.execute_reply.started":"2022-02-27T17:34:26.688645Z","shell.execute_reply":"2022-02-27T17:34:27.750577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### (b) Energy","metadata":{}},{"cell_type":"code","source":"train_LSTM(train_loader_energy, val_loader_energy, epochs = 30,\n           save_dir = 'LSTM_energy', early_stopping=False)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-02-28T01:48:45.633647Z","iopub.execute_input":"2022-02-28T01:48:45.634444Z","iopub.status.idle":"2022-02-28T02:03:23.837515Z","shell.execute_reply.started":"2022-02-28T01:48:45.634393Z","shell.execute_reply":"2022-02-28T02:03:23.836817Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rho_LSTM_energy = test_lstm_multitask(val_loader_energy, 'LSTM_energy')","metadata":{"execution":{"iopub.status.busy":"2022-02-28T02:03:23.840145Z","iopub.execute_input":"2022-02-28T02:03:23.840627Z","iopub.status.idle":"2022-02-28T02:03:26.230585Z","shell.execute_reply.started":"2022-02-28T02:03:23.840593Z","shell.execute_reply":"2022-02-28T02:03:26.229777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# CNN\ntrain_CNN(train_loader_energy, val_loader_energy, epochs = 30, batch_size = 16, save_dir = 'CNN_energy', regression=True, early_stopping = False)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-02-27T17:34:38.195621Z","iopub.execute_input":"2022-02-27T17:34:38.198419Z","iopub.status.idle":"2022-02-27T17:37:02.9227Z","shell.execute_reply.started":"2022-02-27T17:34:38.198371Z","shell.execute_reply":"2022-02-27T17:37:02.922025Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rho_CNN_energy = test_cnn_multitask(val_loader_energy,'CNN_energy')","metadata":{"execution":{"iopub.status.busy":"2022-02-27T17:37:02.924325Z","iopub.execute_input":"2022-02-27T17:37:02.924654Z","iopub.status.idle":"2022-02-27T17:37:03.836413Z","shell.execute_reply.started":"2022-02-27T17:37:02.924608Z","shell.execute_reply":"2022-02-27T17:37:03.835665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### (c) Danceability","metadata":{}},{"cell_type":"code","source":"train_LSTM(train_loader_danceability, val_loader_danceability, epochs = 30,\n           save_dir = 'LSTM_danceability', early_stopping=False)","metadata":{"execution":{"iopub.status.busy":"2022-02-27T23:40:20.522388Z","iopub.execute_input":"2022-02-27T23:40:20.523092Z","iopub.status.idle":"2022-02-27T23:46:44.400115Z","shell.execute_reply.started":"2022-02-27T23:40:20.523056Z","shell.execute_reply":"2022-02-27T23:46:44.398607Z"},"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rho_LSTM_dance = test_lstm_multitask(val_loader_danceability, 'LSTM_danceability')","metadata":{"execution":{"iopub.status.busy":"2022-02-27T23:46:44.401777Z","iopub.execute_input":"2022-02-27T23:46:44.402011Z","iopub.status.idle":"2022-02-27T23:46:45.872042Z","shell.execute_reply.started":"2022-02-27T23:46:44.40198Z","shell.execute_reply":"2022-02-27T23:46:45.871274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# CNN\ntrain_CNN(train_loader_danceability, val_loader_danceability, epochs = 30, batch_size = 16, save_dir = 'CNN_dance', regression=True, early_stopping = False)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-02-27T17:38:26.377679Z","iopub.execute_input":"2022-02-27T17:38:26.378275Z","iopub.status.idle":"2022-02-27T17:40:51.405176Z","shell.execute_reply.started":"2022-02-27T17:38:26.37824Z","shell.execute_reply":"2022-02-27T17:40:51.404481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rho_CNN_dance = test_cnn_multitask(val_loader_danceability,'CNN_dance')","metadata":{"execution":{"iopub.status.busy":"2022-02-27T17:40:51.406859Z","iopub.execute_input":"2022-02-27T17:40:51.407133Z","iopub.status.idle":"2022-02-27T17:40:52.446844Z","shell.execute_reply.started":"2022-02-27T17:40:51.407095Z","shell.execute_reply":"2022-02-27T17:40:52.446051Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Mean Spearman Correlations per Model","metadata":{}},{"cell_type":"code","source":"rho_LSTM_mean = np.mean([rho_LSTM_valence, rho_LSTM_energy, rho_LSTM_dance])\nprint('LSTM Mean Spearman Correlation: ', rho_LSTM_mean)","metadata":{"execution":{"iopub.status.busy":"2022-02-27T23:46:45.873163Z","iopub.execute_input":"2022-02-27T23:46:45.873411Z","iopub.status.idle":"2022-02-27T23:46:45.880229Z","shell.execute_reply.started":"2022-02-27T23:46:45.873377Z","shell.execute_reply":"2022-02-27T23:46:45.879448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rho_CNN_mean = np.mean([rho_CNN_valence, rho_CNN_energy, rho_CNN_dance])\nprint('CNN Mean Spearman Correlation: ', rho_CNN_mean)","metadata":{"execution":{"iopub.status.busy":"2022-02-27T18:06:04.906062Z","iopub.execute_input":"2022-02-27T18:06:04.906507Z","iopub.status.idle":"2022-02-27T18:06:04.912409Z","shell.execute_reply.started":"2022-02-27T18:06:04.906472Z","shell.execute_reply":"2022-02-27T18:06:04.911655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Βήμα 9: Transfer Learning","metadata":{}},{"cell_type":"code","source":"# Train for only a few epochs\ntrain_CNN(train_loader_energy, val_loader_energy, epochs = 10, \n          batch_size = 32, save_dir = 'CNN_step7', \n          regression=True, early_stopping = False, load_model = True)","metadata":{"execution":{"iopub.status.busy":"2022-02-28T02:46:31.127843Z","iopub.execute_input":"2022-02-28T02:46:31.128109Z","iopub.status.idle":"2022-02-28T02:47:06.656048Z","shell.execute_reply.started":"2022-02-28T02:46:31.128072Z","shell.execute_reply":"2022-02-28T02:47:06.655394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rho_CNN_energy_transfer = test_cnn_multitask(val_loader_energy,'CNN_transfer')","metadata":{"execution":{"iopub.status.busy":"2022-02-28T02:47:12.927716Z","iopub.execute_input":"2022-02-28T02:47:12.927999Z","iopub.status.idle":"2022-02-28T02:47:13.860184Z","shell.execute_reply.started":"2022-02-28T02:47:12.927969Z","shell.execute_reply":"2022-02-28T02:47:13.859321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Βήμα 10: Multitask Learning","metadata":{}},{"cell_type":"code","source":"class MultitaskDataset(Dataset):\n    def __init__(self, path, max_length=-1, read_spec_fn=read_spectrogram, mode = 'mel_spec',\n                 label_type='all', train = True):\n        if train:\n            p = os.path.join(path, 'train')\n        else:\n            p = os.path.join(path, 'test')\n\n        self.label_type = label_type\n        self.index = os.path.join(path, \"train_labels.txt\")\n        self.files, labels = self.get_files_labels(self.index)\n        self.feats = [read_spec_fn(os.path.join(p, f), mode) for f in self.files]\n        self.feat_dim = self.feats[0].shape[1]\n        self.lengths = [len(i) for i in self.feats]\n        self.max_length = max(self.lengths) if max_length <= 0 else max_length\n        self.zero_pad_and_stack = PaddingTransform(self.max_length) \n        if isinstance(labels, (list, tuple)):\n            self.labels = np.array(labels)\n\n    def get_files_labels(self, txt):\n        with open(txt, 'r') as fd:\n            lines = [l.split(',') for l in fd.readlines()[1:]]\n        files, labels = [], []\n        for l in lines:\n            if self.label_type == 'valence':\n                labels.append(float(l[1]))\n            elif self.label_type == 'energy':\n                labels.append(float(l[2]))\n            elif self.label_type == 'danceability':\n                labels.append(float(l[3].strip(\"\\n\")))\n            else:\n                labels.append([float(l[1]), float(l[2]), float(l[3].strip(\"\\n\"))])\n            # Kaggle automatically unzips the npy.gz format so this hack is needed\n            _id = l[0]\n            npy_file = '{}.fused.full.npy'.format(_id)\n            files.append(npy_file)\n        return files, labels\n    \n\n    def __getitem__(self, item):\n        # Return a tuple in the form (padded_feats, valence, energy, danceability, length)\n        l = min(self.lengths[item], self.max_length)\n        return self.zero_pad_and_stack(self.feats[item]), self.labels[item], l\n\n    def __len__(self):\n        return len(self.labels)","metadata":{"execution":{"iopub.status.busy":"2022-02-28T20:19:57.841614Z","iopub.execute_input":"2022-02-28T20:19:57.842286Z","iopub.status.idle":"2022-02-28T20:19:57.855819Z","shell.execute_reply.started":"2022-02-28T20:19:57.842249Z","shell.execute_reply":"2022-02-28T20:19:57.855115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"multitask_dataset = MultitaskDataset('../input/patreco3-multitask-affective-music/data/multitask_dataset/',\n                            max_length=-1, label_type = 'all')","metadata":{"execution":{"iopub.status.busy":"2022-02-28T20:19:58.228333Z","iopub.execute_input":"2022-02-28T20:19:58.228883Z","iopub.status.idle":"2022-02-28T20:20:18.213456Z","shell.execute_reply.started":"2022-02-28T20:19:58.228845Z","shell.execute_reply":"2022-02-28T20:20:18.212704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_loader_multitask, val_loader_multitask = torch_train_val_split(multitask_dataset,\n                                                                     batch_train=32, \n                                                                     batch_eval=32, val_size=.2)","metadata":{"execution":{"iopub.status.busy":"2022-02-28T20:22:02.163172Z","iopub.execute_input":"2022-02-28T20:22:02.163634Z","iopub.status.idle":"2022-02-28T20:22:02.167658Z","shell.execute_reply.started":"2022-02-28T20:22:02.163593Z","shell.execute_reply":"2022-02-28T20:22:02.166991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Our Loss Function as sum of all losses for valence, energy, danceability\nclass Multitask_loss(nn.Module):\n    def forward(preds, golds):\n        criterion = nn.MSELoss()\n        loss_valence = criterion(preds[:,0], golds[:,0])\n        loss_energy = criterion(preds[:,1], golds[:,1])\n        loss_danceability = criterion(preds[:,2], golds[:,2])\n        \n        return loss_valence + loss_energy + loss_danceability","metadata":{"execution":{"iopub.status.busy":"2022-02-28T20:19:51.480284Z","iopub.execute_input":"2022-02-28T20:19:51.480559Z","iopub.status.idle":"2022-02-28T20:19:51.486846Z","shell.execute_reply.started":"2022-02-28T20:19:51.480528Z","shell.execute_reply":"2022-02-28T20:19:51.48613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function that Evaluates a Convolutional Neural Network\ndef eval_CNN_multitask(dataloader, model):\n    \n    total_loss = 0.0\n    model.eval() # switch to evaluation mode\n    \n    y_gold = []\n    y_pred = []\n    \n    with torch.no_grad(): # don't keep gradients\n        for idx, batch in enumerate(dataloader, 1):\n            \n            (inputs, labels, lengths) = batch\n\n            # Move the batch tensors to the right device\n            inputs = inputs.to(device).float()\n            labels = labels.to(device).float()\n            \n            # Forward Pass\n            y_preds = model(inputs)\n\n            # Compute Loss\n            loss = Multitask_loss.forward(y_preds, labels)\n            prediction = y_preds\n            \n            # Collect Loss and labels\n            total_loss += loss.data.item()\n            \n            y_pred.append(prediction.cpu().numpy())\n            y_gold.append(labels.cpu().numpy())\n\n    return total_loss / idx, (y_gold, y_pred)","metadata":{"execution":{"iopub.status.busy":"2022-02-28T20:20:41.970027Z","iopub.execute_input":"2022-02-28T20:20:41.970285Z","iopub.status.idle":"2022-02-28T20:20:41.97725Z","shell.execute_reply.started":"2022-02-28T20:20:41.970255Z","shell.execute_reply":"2022-02-28T20:20:41.976383Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Main Pipeline that Trains on Train Set and Evaluates on Validation Set\ndef train_CNN_multitask(data_loader, val_loader, epochs, batch_size, save_dir, lr = 0.001, \n              weight_decay = 0.0001, early_stopping = True):\n\n    # Define Hyperparameters and CNN Model        \n    model_cnn = CNN_2D(output_dim = 3)\n        \n    model_cnn.to(device).float()\n    optimizer = torch.optim.Adam(model_cnn.parameters(), lr=lr,weight_decay=0.0001)\n    \n    train_loss_min = np.Inf\n    loss_values_train = []\n    loss_values_val = []\n    \n    # Early Stopping Hyperparameters\n    counter=0\n    best_val_loss = 999999\n    max_increases = 10\n    \n    model_cnn.train()    \n    for i in range(epochs):\n        running_loss_train=0.0\n        running_loss_val=0.0\n        train_losses=[]\n        for idx, batch in enumerate(data_loader):\n             # Unpack Batch\n            (inputs, labels, lengths) = batch\n            inputs, labels, lengths= inputs.to(device), labels.to(device),lengths.to(device)\n            model_cnn.zero_grad()\n            output =  model_cnn(inputs.float())\n            loss = Multitask_loss.forward(output.squeeze(), labels.float())\n            \n            running_loss_train =+ loss.item() * batch_size\n            train_losses.append(loss.item())\n            loss.backward()\n            optimizer.step()\n            \n        val_loss, (y_gold, y_pred)  = eval_CNN_multitask(val_loader, model_cnn)\n        loss_values_val.append(val_loss)\n\n        print(\"Epoch: {}/{}:\".format(i+1, epochs),\n              \"Train Loss: {:.6f} - \".format(loss.item()),\n              \"Val Loss: {:.6f}\".format(val_loss))\n        \n        loss_values_train.append(np.mean(train_losses))\n        \n        # Apply Early Stopping Techniques\n        if val_loss < best_val_loss:\n            torch.save(model_cnn.state_dict(),save_dir) # checkpoint\n            best_val_loss = val_loss\n            gold = y_gold\n            pred = y_pred\n            counter = 0 # reset counter\n        else:\n            counter += 1\n\n        if early_stopping:\n            if counter == max_increases: # 10 times in a row no loss improvement - break\n                print('Early Stopping')\n                break\n            \n    plt.figure()\n    plt.plot(range(len(loss_values_train)),loss_values_train, label = 'Train Loss')\n    plt.plot(range(len(loss_values_val)), loss_values_val, label = 'Validation Loss')\n    plt.xlabel('Epochs')\n    plt.legend()\n    plt.show()\n    \n    #torch.save(model_cnn.state_dict(),save_dir) # save best model","metadata":{"execution":{"iopub.status.busy":"2022-02-28T20:20:47.083297Z","iopub.execute_input":"2022-02-28T20:20:47.083701Z","iopub.status.idle":"2022-02-28T20:20:47.098935Z","shell.execute_reply.started":"2022-02-28T20:20:47.083665Z","shell.execute_reply":"2022-02-28T20:20:47.097349Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_CNN_multitask(train_loader_multitask, val_loader_multitask, epochs = 20, batch_size = 16,\n                    save_dir = 'CNN_step10', early_stopping = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluate with Spearman Correlation\ndef test_cnn_all_labels(test_loader, model_dir):\n    \n    # Fetch Model\n    model_cnn=CNN_2D(output_dim=3).to(device).float()\n    model_cnn.load_state_dict(torch.load(model_dir))\n    \n    test_losses = []\n    y_pred_test=[]\n    y_true=[]\n    model_cnn.eval()\n    \n    for inputs,labels,lengths in test_loader:\n        inputs,labels,lengths= inputs.to(device), labels.to(device),lengths.to(device)\n        output = model_cnn(inputs.float())\n        y_pred_test.append(output.data.tolist())\n        y_true.append(labels.tolist())\n    \n    true = np.array(y_true).flatten()\n    pred = np.array(y_pred_test).flatten()\n\n    valence_pred, energy_pred, dance_pred = [], [], []\n    valence_true, energy_true, dance_true = [], [], []\n\n    for i in range(0,np.shape(true)[0],3):\n        valence_true.append(true[i])\n        energy_true.append(true[i+1])\n        dance_true.append(true[i+2])\n        \n        valence_pred.append(pred[i])\n        energy_pred.append(pred[i+1])\n        dance_pred.append(pred[i+2])\n    \n    # Ger Spearmann Correlation\n \n    rho_valence = spearmanr(valence_true,valence_pred).correlation\n    rho_energy = spearmanr(energy_true,energy_pred).correlation\n    rho_danceability = spearmanr(dance_true,dance_pred).correlation\n\n    print('\\nValence Spearman Correlation: {:.6f} \\n'.format(rho_valence))\n    print('\\nEnergy Spearman Correlation: {:.6f} \\n'.format(rho_energy))\n    print('\\nDanceability Spearman Correlation: {:.6f} \\n'.format(rho_danceability))\n    print('\\nMean Spearman Correlation: {:.6f} \\n'.format(np.mean([rho_valence, rho_energy, rho_danceability])))\n\n    \n    return rho_valence, rho_energy, rho_danceability","metadata":{"execution":{"iopub.status.busy":"2022-02-28T20:20:49.651534Z","iopub.execute_input":"2022-02-28T20:20:49.65221Z","iopub.status.idle":"2022-02-28T20:20:49.664104Z","shell.execute_reply.started":"2022-02-28T20:20:49.652169Z","shell.execute_reply":"2022-02-28T20:20:49.663072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"valence, energy, dance = test_cnn_all_labels(val_loader_multitask, 'CNN_step10')","metadata":{"execution":{"iopub.status.busy":"2022-02-28T20:22:15.615721Z","iopub.execute_input":"2022-02-28T20:22:15.616538Z","iopub.status.idle":"2022-02-28T20:22:16.339613Z","shell.execute_reply.started":"2022-02-28T20:22:15.616493Z","shell.execute_reply":"2022-02-28T20:22:16.33886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Βήμα 11: Υποβολή στο Kaggle","metadata":{}},{"cell_type":"code","source":"CNN_multi = CNN_2D(output_dim=3).to(device).float()\nCNN_multi.load_state_dict(torch.load('CNN_step10'))","metadata":{"execution":{"iopub.status.busy":"2022-02-28T20:22:56.142437Z","iopub.execute_input":"2022-02-28T20:22:56.142973Z","iopub.status.idle":"2022-02-28T20:22:56.168118Z","shell.execute_reply.started":"2022-02-28T20:22:56.142933Z","shell.execute_reply":"2022-02-28T20:22:56.167471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class MultitaskDatasetTest(Dataset):\n    def __init__(self, path, max_length=-1, read_spec_fn=read_spectrogram, label_type='all', mode = 'mel_spec'):\n        p = os.path.join(path, 'test')\n        self.label_type = label_type\n        self.feats = []\n        self.files = []\n        for f in os.listdir(p):\n            self.feats.append(read_spec_fn(os.path.join(p, f), mode))\n            self.files.append(f.split('.')[0])\n        self.feat_dim = self.feats[0].shape[1]\n        self.lengths = [len(i) for i in self.feats]\n        self.max_length = max(self.lengths) if max_length <= 0 else max_length\n        self.zero_pad_and_stack = PaddingTransform(self.max_length) \n\n    def __getitem__(self, item):\n        # Return a tuple in the form (padded_feats, valence, energy, danceability, length)\n        l = min(self.lengths[item], self.max_length)\n        return self.zero_pad_and_stack(self.feats[item]), l, self.files[item]\n\n    def __len__(self):\n        return len(self.feats)","metadata":{"execution":{"iopub.status.busy":"2022-02-28T20:23:00.690663Z","iopub.execute_input":"2022-02-28T20:23:00.691246Z","iopub.status.idle":"2022-02-28T20:23:00.700758Z","shell.execute_reply.started":"2022-02-28T20:23:00.691205Z","shell.execute_reply":"2022-02-28T20:23:00.699747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Read Test Dataset\ntest_multitask = MultitaskDatasetTest(\n         '../input/patreco3-multitask-affective-music/data/multitask_dataset/',\n         max_length=-1,\n         read_spec_fn=read_spectrogram)","metadata":{"execution":{"iopub.status.busy":"2022-02-28T20:23:02.653369Z","iopub.execute_input":"2022-02-28T20:23:02.653654Z","iopub.status.idle":"2022-02-28T20:23:10.439496Z","shell.execute_reply.started":"2022-02-28T20:23:02.653622Z","shell.execute_reply":"2022-02-28T20:23:10.438698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create DataLoader\ntest_loader_multitask, _ = torch_train_val_split(test_multitask,batch_train=32,batch_eval=32, val_size=0)","metadata":{"execution":{"iopub.status.busy":"2022-02-28T20:23:49.987246Z","iopub.execute_input":"2022-02-28T20:23:49.987505Z","iopub.status.idle":"2022-02-28T20:23:49.993051Z","shell.execute_reply.started":"2022-02-28T20:23:49.987476Z","shell.execute_reply":"2022-02-28T20:23:49.992279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluate with Spearman Correlation\ndef test_cnn_kaggle(test_loader, model_dir):\n    \n    # Fetch Model\n    model_cnn=CNN_2D(output_dim=3).to(device).float()\n    model_cnn.load_state_dict(torch.load(model_dir))\n    \n    test_losses = []\n    y_pred_test=[]\n    y_true=[]\n    filenames = []\n    all_preds = []\n    model_cnn.eval()\n    filenames = []\n    for inputs,lengths,filename in test_loader:\n        filenames.append(filename)\n        inputs=inputs.to(device)\n        output = model_cnn(inputs.float())\n        y_pred_test.append(output.data.tolist())\n    \n    pred = np.array(y_pred_test).flatten()\n    \n    return filenames, pred","metadata":{"execution":{"iopub.status.busy":"2022-02-28T20:24:00.59127Z","iopub.execute_input":"2022-02-28T20:24:00.591532Z","iopub.status.idle":"2022-02-28T20:24:00.598816Z","shell.execute_reply.started":"2022-02-28T20:24:00.591502Z","shell.execute_reply":"2022-02-28T20:24:00.597762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"filenames, all_preds = test_cnn_kaggle(test_loader_multitask, 'CNN_step10 (1)')","metadata":{"execution":{"iopub.status.busy":"2022-02-28T20:24:07.056955Z","iopub.execute_input":"2022-02-28T20:24:07.057513Z","iopub.status.idle":"2022-02-28T20:24:08.294818Z","shell.execute_reply.started":"2022-02-28T20:24:07.057473Z","shell.execute_reply":"2022-02-28T20:24:08.293782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final = np.array([])\ntemp_names = np.array([])\nfor i in filenames:\n    for j in i:\n        temp_names = np.append(temp_names, j)\n\nresults = []\nfor i in all_preds:\n    for j in i:\n        results.append(j)\n\nkaggle_res = np.zeros((375,4))\nkaggle_res[:, 0] = np.array(temp_names)\nkaggle_res[:, 1:] = np.array(results)","metadata":{"execution":{"iopub.status.busy":"2022-02-28T20:24:09.977105Z","iopub.execute_input":"2022-02-28T20:24:09.977886Z","iopub.status.idle":"2022-02-28T20:24:09.99089Z","shell.execute_reply.started":"2022-02-28T20:24:09.977844Z","shell.execute_reply":"2022-02-28T20:24:09.990079Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import csv\nwith open('final.csv', 'w', newline='\\n') as file:\n        writer = csv.writer(file)\n        writer.writerow([\"Id.fused.full.npy.gz\", \"valence\", \"energy\", \"danceability\"])\n        for i in range(375):\n            tt = []\n            tt.append(temp_names[i]+'.fused.full.npy.gz')\n            tt.append(str(results[i][0]))\n            tt.append(str(results[i][1]))\n            tt.append(str(results[i][2]))\n            writer.writerow(tt)","metadata":{"execution":{"iopub.status.busy":"2022-02-28T20:24:10.620964Z","iopub.execute_input":"2022-02-28T20:24:10.621463Z","iopub.status.idle":"2022-02-28T20:24:10.633557Z","shell.execute_reply.started":"2022-02-28T20:24:10.621424Z","shell.execute_reply":"2022-02-28T20:24:10.632816Z"},"trusted":true},"execution_count":null,"outputs":[]}]}